{
  "hash": "af056fdc474409ba50a473e0df5b30ff",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Modello bayesiano di regressione lineare bivariata {#sec-linmod-bayesian-reg}\n\n::: callout-note\n## Cosa Imparerai in Questo Capitolo\n\n- Comprendere il modello di regressione bayesiano e come si differenzia dall'approccio frequentista.\n- Interpretare i parametri stimati in un contesto bayesiano e confrontarli con quelli frequentisti.\n- Familiarizzare con l'uso di Stan e *{brms}* nella regressione.\n- Interpretare le previsioni del modello bayesiano e le verifiche predittive a posteriori.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere *Regression and Other Stories* [@gelman2021regression].\n  - Prestare particolare attenzione ai capitoli 1 \"Overeview, 6, \"Background on Regression Modeling,\" 7, \"Linear Regression with a Single Predictor\" e 8, \"Fitting regression models\", che offrono una guida dettagliata al modello di regressione bivariato.\n:::\n\n::: callout-important\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, see, brms)\n```\n:::\n\n\n\n:::\n\n## Introduzione \n\nIn questa sezione della dispensa, esploreremo il modello di regressione lineare bivariata bayesiano, confrontandolo con l'approccio frequentista. Questi modelli statistici sono impiegati principalmente per due finalità: inferenza e previsione. Mentre la previsione mira a descrivere le associazioni tra le variabili, l'inferenza si focalizza sul delineare relazioni causali tramite un modello lineare. È importante notare che, sebbene la capacità predittiva di un modello possa essere verificata empiricamente, l'uso della regressione per dedurre causalità richiede una rigorosa progettazione sperimentale o quasi-sperimentale, nonché una solida base di giustificazioni per le ipotesi utilizzate. Bisogna inoltre tenere presente che l'analisi di regressione costituisce una forma di media ponderata, e pertanto i suoi risultati possono essere influenzati da bias e specificità del dataset utilizzato.\n\n## Modello di Regressione Bayesiano\n\nDopo aver confermato che il modello di regressione recupera in modo affidabile i valori teorici dell'intercetta e della pendenza della retta di regressione, procediamo ora ad applicare il modello a dataset reali. L'approccio bayesiano si distingue dai metodi dei minimi quadrati o della massima verosimiglianza in quanto non si limita a determinare i parametri che meglio si adattano ai dati osservati secondo un criterio prefissato. Al contrario, integra queste stime con informazioni a priori sui parametri stessi, combinando la verosimiglianza dei dati con una distribuzione a priori che rappresenta le ipotesi o le conoscenze preesistenti. In questo modo, l'inferenza bayesiana diventa un processo di aggiornamento delle credenze: la distribuzione a posteriori dei parametri riflette la conoscenza aggiornata dopo aver osservato i dati. A differenza dei metodi classici che forniscono stime puntuali, l'inferenza bayesiana produce distribuzioni a posteriori che esprimono la probabilità di ogni possibile valore dei parametri, considerando l'incertezza complessiva nel modello.\n\nNel contesto di un modello lineare bayesiano, adottiamo le seguenti convenzioni: le variabili di risposta sono indicate con $y$, le variabili predittive (note anche come covariate o caratteristiche) con $x$, e l'indice di osservazione con $i$, che va da 1 al numero totale di osservazioni. La verosimiglianza di un semplice modello lineare (gaussiano) si può esprimere come:\n\n$$ \ny_i \\sim Normale(\\mu_i, \\sigma), \n$$\n\ndove $\\mu_i = b_0 + b_1x_i$. La distribuzione normale univariata è definita in termini di media e deviazione standard.\n\nNel modello bayesiano lineare, i parametri principali sono l'intercetta $b_0$ e il coefficiente $b_1$ associato alla variabile predittiva. Questi parametri insieme formano il predittore lineare $\\mu$. Il parametro $\\sigma$ rappresenta la deviazione standard residua, ovvero la variabilità che non può essere spiegata dal modello lineare e che cattura l'errore o il \"rumore\" presente nei dati.\n\nPer esempio, se desideriamo modellare la relazione tra ansia di stato ($y$) e Tense Arousal ($x$), l'approccio bayesiano permette di strutturare il modello in modo simile a quanto fatto con i metodi classici. Anche qui, si assume che gli errori siano indipendenti tra loro, distribuiti normalmente con media zero e varianza costante $\\sigma^2$. Tuttavia, l'approccio bayesiano consente anche di specificare distribuzioni a priori per i parametri del modello ($b_0$, $b_1$, $\\sigma$), che rappresentano la conoscenza iniziale sui parametri prima di osservare i dati.\n\nDopo aver raccolto i dati, si utilizza il teorema di Bayes per aggiornare queste distribuzioni a priori e ottenere le distribuzioni a posteriori dei parametri. Le distribuzioni a posteriori combinano l'informazione fornita dai dati con le credenze iniziali, offrendo stime dei parametri che riflettono sia l'evidenza empirica che le conoscenze preesistenti, garantendo un'inferenza più robusta e flessibile.\n\n### Verosimiglianza  \n\nNel modello di regressione lineare bayesiano bivariato, la verosimiglianza che descrive la relazione tra ansia di stato (y) e Tense Arousal (x) assume che:\n$$ y \\sim Normale(\\alpha + \\beta x, \\sigma) $$\nQuesto implica che i valori osservati di y sono distribuiti normalmente attorno alla retta di regressione $\\alpha + \\beta x$, con una deviazione standard $\\sigma$. In altre parole, ogni osservazione di y è una combinazione lineare dell'intercetta $\\alpha$, del coefficiente $\\beta$ che moltiplica la variabile predittiva x, e di un termine di errore distribuito normalmente.\n\n### Distribuzioni a Priori \n\nPer implementare l'approccio bayesiano, definiamo delle distribuzioni a priori per i parametri $\\alpha$, $\\beta$, e $\\sigma$. Anche se è possibile utilizzare delle distribuzioni a priori uniformi, che esprimono una mancanza di conoscenza specifica o una neutralità nelle credenze iniziali sui valori di questi parametri, questa pratica è scoraggiata. È invece consigliato, in assenza di informazioni preliminari, di utilizzare dei prior debolmente informativi:\n\n$$ \\alpha \\sim \\mathcal{N}(0, 2.5), $$\n\n$$ \n\\beta \\sim \\mathcal{N}(0, 2.5), \n$$\n\n$$ \n\\sigma \\sim \\text{Cauchy}(0, 2.5) \n$$\n\n### Distribuzioni a Posteriori  \n\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza con le distribuzioni a priori mediante il teorema di Bayes. Queste distribuzioni a posteriori riflettono il nostro stato di conoscenza sui parametri dopo aver osservato i dati, incorporando sia le informazioni contenute nei dati che le credenze iniziali espresse dalle distribuzioni a priori. L'approccio bayesiano non solo fornisce stime dei parametri, ma anche una quantificazione dell'incertezza associata a queste stime, rendendo il metodo particolarmente utile in situazioni con dati limitati o incertezza rilevante.\n\n## Adattare una Retta di Regressione a Dati Simulati  \n\nSimuliamo 200 osservazioni di $x$ e $y$, dove $y$ è generato seguendo i parametri specificati. Questo ci permette di modellare e comprendere in modo più completo e robusto la relazione tra ansia di stato e Tense Arousal, integrando informazioni preesistenti con nuove evidenze empiriche.\n\nIn sintesi, il modello di regressione bayesiano può essere riassunto come segue. La verosimiglianza è data da:\n\n$$ \ny_i \\sim \\mathcal{N}(\\alpha + \\beta \\cdot x_i; \\sigma) \n$$\n\nDefiniamo i parametri e simuliamo i dati.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\n# Definizione delle variabili\nx <- 1:20\nn <- length(x)\na <- 0.2\nb <- 0.3\nsigma <- 0.5\n\n# Generazione di y\ny <- a + b * x + sigma * rnorm(n)\n\n# Creazione del dataframe\nfake <- tibble(x = x, y = y)\nhead(fake)\n#> # A tibble: 6 × 2\n#>       x     y\n#>   <int> <dbl>\n#> 1     1 0.220\n#> 2     2 0.685\n#> 3     3 1.88 \n#> 4     4 1.44 \n#> 5     5 1.76 \n#> 6     6 2.86\n```\n:::\n\n\n\n\nAdattiamo quindi ai dati un modello di regressione bayesiano utilizzando *{cmdstanr}*. Scriviamo il modello in un file Stan. Salviamo il file come `linear-regression.stan` e compiliamo il modello:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- cmdstan_model(\nhere::here(\"stan\", \"linear-regression.stan\")\n)\n```\n:::\n\n\n\n\nIl modello ha questa forma:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel$print()\n#> // all data should be scaled to mean 0 and std 1:\n#> data {\n#>   int<lower=1> N;\n#>   vector[N] x;\n#>   vector[N] y;\n#> }\n#> parameters {\n#>   real alpha;\n#>   real beta;\n#>   real<lower=0> sigma;\n#> }\n#> model {\n#>   y ~ normal(alpha + beta * x, sigma);\n#>   alpha ~ normal(0, 2.5);\n#>   beta ~ normal(0, 2.5);\n#>   sigma ~ cauchy(0, 2.5);\n#> }\n#> generated quantities {\n#>   vector[N] log_lik;\n#>   vector[N] y_rep;\n#>   for (n in 1:N) {\n#>     log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n#>     y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n#>   }\n#> }\n```\n:::\n\n\n\n\nPrepariamo i dati nel formato appropriato per Stan:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_data <- list(\n  N = nrow(fake),\n  x = fake$x,\n  y = fake$y\n)\n```\n:::\n\n\n\n\nEseguiamo il campionamento:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- model$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n```\n:::\n\n\n\n\nLe tracce dei parametri si ottengono nel modo seguente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_trace(\n  fit$draws(c(\"alpha\", \"beta\", \"sigma\"))\n)\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-7-1.png){width=576}\n:::\n:::\n\n\n\n\nGeneriamo gli istogrammi delle distribuzioni a posteriori dei parametri:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_hist(fit$draws(c(\"alpha\", \"beta\", \"sigma\")))\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-8-1.png){width=576}\n:::\n:::\n\n\n\n\nNel grafico seguente distinguiamo tra le varie catene:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_dens_overlay(fit$draws(c(\"alpha\", \"beta\", \"sigma\")))\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-9-1.png){width=576}\n:::\n:::\n\n\n\n\nPossiamo anche esaminare la covariazione delle stime a posteriori dei parametri:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_pairs(\n  fit$draws(c(\"alpha\", \"beta\", \"sigma\")),\n  off_diag_args = list(size = 1.5)\n)\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-10-1.png){width=576}\n:::\n:::\n\n\n\n\nEsaminiamo l'autocorrelazione tra le stime a posteriori di `beta`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_acf(fit$draws(c(\"beta\")))\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-11-1.png){width=576}\n:::\n:::\n\n\n\n\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 × 10\n#>   variable  mean median     sd    mad      q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    0.349  0.351 0.256  0.239  -0.0692 0.763  1.00    2650.    2722.\n#> 2 beta     0.292  0.292 0.0213 0.0199  0.258  0.328  1.00    2727.    2404.\n#> 3 sigma    0.535  0.518 0.102  0.0908  0.399  0.726  1.00    2914.    3110.\n```\n:::\n\n\n\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L'intercetta è stata stimata attorno a 0.2, con un'incertezza che varia tra 0.15 e 0.30. Questo risultato rientra negli intervalli di credibilità previsti e non sorprende, confermando l'accuratezza del modello. Analogamente, per la pendenza $b$, l'intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l'incertezza sui parametri, anche con campioni di dimensioni ridotte.\n\nDisegniamo un diagramma a dispersione con la retta di regressione stimata.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estrazione dei parametri stimati\nposterior_summary <- fit$summary(c(\"alpha\", \"beta\"))\nalpha_hat <- posterior_summary$mean[1]\nbeta_hat <- posterior_summary$mean[2]\n# Scatterplot con la retta di regressione\nggplot(fake, aes(x = x, y = y)) +\n  geom_point(color = \"blue\") +\n  geom_abline(intercept = alpha_hat, slope = beta_hat, color = \"red\") +\n  labs(\n  title = \"Scatterplot con Retta di Regressione Stimata\",\n  x = \"x\", \n  y = \"y\"\n)\n```\n\n::: {.cell-output-display}\n![](01_reglin_bayes_files/figure-html/unnamed-chunk-13-1.png){width=576}\n:::\n:::\n\n\n\n\n## Simulazione di Livelli di Copertura\n\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n# Parametri veri\na_true <- 0.2\nb_true <- 0.3\nsigma_true <- 0.5\n# Numero di simulazioni\nnum_simulations <- 1000\n# Conteggio delle coperture\ncoverage_a <- 0\ncoverage_b <- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x <- 1:20\n  y <- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit <- lm(y ~ x)\n  ci <- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] <= a_true & ci[1, 2] >= a_true) {\n    coverage_a <- coverage_a + 1\n  }\n  if (ci[2,1] <= b_true & ci[2, 2] >= b_true) {\n    coverage_b <- coverage_b + 1\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#> Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#> Coverage for b: 0.955\n```\n:::\n\n\n\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l'approccio frequentista corrispondono strettamente ai livelli teorici attesi.\n\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Al fine di semplificare la simulazione, invece di utilizzare `cmdstanr` per calcolare le stime posteriori di `alpha` e `beta`, impiegheremo la funzione `brm()` del pacchetto *{brms}*. Questa funzione, che si basa su Stan, offre un'interfaccia di più alto livello che facilita notevolmente l'uso. Le funzionalità del pacchetto *{brms}* verranno approfondite nel @sec-linar-models-brms.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definizione dei parametri\nset.seed(23)\nn_fake <- 1000\ncover_68 <- rep(NA, n_fake)\ncover_95 <- rep(NA, n_fake)\na <- 0.2 # Intercetta vera\nb <- 0.3 # Pendenza vera\nsigma <- 0.5 # Deviazione standard vera\nx <- 1:20 # Variabile indipendente\nn <- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y <- a + b * x + rnorm(n, 0, sigma)\n  fake <- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit <- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary <- summary(fit)$fixed\n  b_hat <- posterior_summary[\"x\", \"Estimate\"]\n  b_se <- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] <- abs(b - b_hat) < b_se\n  cover_95[s] <- abs(b - b_hat) < 2 * b_se\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summarize the coverage results\nmean_cover_68 <- mean(cover_68, na.rm = TRUE)\nmean_cover_95 <- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\n#> Coverage for 68% interval: 0.7\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\n#> Coverage for 95% interval: 0.954\n```\n:::\n\n\n\n\nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l'approccio bayesiano si avvicinano ai valori teorici previsti.\n\nTale risultato conferma l'efficacia degli intervalli di confidenza stimati attraverso i modelli bayesiani e frequentisti.\n\n## Confronti, non Effetti\n\n@gelman2021regression sottolineano che i coefficienti di regressione sono spesso denominati \"effetti\", ma questa terminologia può trarre in inganno. Gli \"effetti\", infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con $X = x + 1$ è spesso maggiore o minore (a seconda del segno di $\\beta$) rispetto alla media della sottopopolazione con $X = x$.\n\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall'uso del modello statistico.\n\n## Riflessioni Conclusive\n\nIn questo capitolo, abbiamo adottato una prospettiva bayesiana per stimare i parametri di un modello di regressione bivariato, cogliendo l'opportunità di riflettere sulla natura e sul ruolo dei modelli statistici nella ricerca scientifica, e in particolare nell'ambito psicologico. Come sottolineato da @alexander2023telling, i modelli statistici non sono strumenti per scoprire una verità assoluta, bensì mezzi per interpretare e dare significato ai dati a nostra disposizione. In questa ottica, i modelli non vanno intesi come riproduzioni fedeli della realtà, ma piuttosto come \"lenti\" che ci permettono di mettere a fuoco e comprendere, almeno in parte, il mondo che ci circonda.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] rstan_2.32.6        StanHeaders_2.32.10 brms_2.22.8        \n#>  [4] Rcpp_1.0.13-1       see_0.9.0           posterior_1.6.0    \n#>  [7] cmdstanr_0.8.1.9000 viridis_0.6.5       viridisLite_0.4.2  \n#> [10] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#> [13] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#> [16] knitr_1.49          lubridate_1.9.4     forcats_1.0.0      \n#> [19] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#> [22] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#> [25] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#> [28] here_1.0.1         \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#>  [4] fastmap_1.2.0        TH.data_1.1-2        tensorA_0.36.2.1    \n#>  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#> [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.7-0      \n#> [13] processx_3.8.4       magrittr_2.0.3       compiler_4.4.2      \n#> [16] rlang_1.1.4          tools_4.4.2          utf8_1.2.4          \n#> [19] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#> [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.0.1          \n#> [25] pkgbuild_1.4.5       mnormt_2.1.1         plyr_1.8.9          \n#> [28] abind_1.4-8          multcomp_1.4-26      withr_3.0.2         \n#> [31] stats4_4.4.2         grid_4.4.2           fansi_1.0.6         \n#> [34] inline_0.3.20        xtable_1.8-4         colorspace_2.1-1    \n#> [37] MASS_7.3-61          emmeans_1.10.5       cli_3.6.3           \n#> [40] mvtnorm_1.3-2        rmarkdown_2.29       generics_0.1.3      \n#> [43] RcppParallel_5.1.9   reshape2_1.4.4       tzdb_0.4.0          \n#> [46] splines_4.4.2        parallel_4.4.2       matrixStats_1.4.1   \n#> [49] vctrs_0.6.5          V8_6.0.0             Matrix_1.7-1        \n#> [52] sandwich_3.1-1       jsonlite_1.8.9       hms_1.1.3           \n#> [55] glue_1.8.0           codetools_0.2-20     ps_1.8.1            \n#> [58] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#> [61] QuickJSR_1.4.0       munsell_0.5.1        pillar_1.9.0        \n#> [64] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.5.1            \n#> [67] rprojroot_2.0.4      evaluate_1.0.1       lattice_0.22-6      \n#> [70] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#> [73] nlme_3.1-166         checkmate_2.3.2      xfun_0.49           \n#> [76] zoo_1.8-12           pkgconfig_2.0.3\n```\n:::\n\n\n\n\n## Bibliografia {.unnumbered}\n\n",
    "supporting": [
      "01_reglin_bayes_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}