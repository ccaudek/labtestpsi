{
  "hash": "f891e4ed90758f2764f0dc84dbdd9d7a",
  "result": {
    "engine": "knitr",
    "markdown": "# Confronto tra le medie di due gruppi {#sec-linear-models-two-groups}\n\n::: callout-note\n## In questo capitolo imparerai a\n\n- condurre un confronto bayesiano tra le medie di due gruppi utilizzando la  funzione `brm()` del pacchetto *{brms}*.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Consultare l'articolo \"Bayesian estimation supersedes the t test\" [@kruschke2013bayesian]. \n:::\n\n::: callout-important\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(psych)\n```\n:::\n\n\n\n\n:::\n\n## Introduzione\n\nIn questo capitolo, adotteremo invece un **approccio frequentista**, tipico dell’analisi classica di regressione lineare e del test t di Student. Mostreremo come il confronto tra due medie, solitamente effettuato con un test t per campioni indipendenti, possa essere visto come un caso particolare di un modello di regressione lineare. Introdurremo una variabile indicatrice (o dummy) che codifica l’appartenenza dell’osservazione a uno dei due gruppi, e vedremo come l’inferenza sul coefficiente di questa variabile nel modello di regressione equivalga a effettuare un test t.\n\nIn altre parole, il modello di regressione fornirà una prospettiva unificata: invece di considerare due medie separate, potremo modellare la variabile risposta come dipendente da un predittore binario. Ciò non solo riproduce i risultati del test t, ma apre la strada a estensioni più complesse, come l’aggiunta di altri predittori, di interazioni o il controllo di covariate.\n\n---\n\n## Il Test t come Caso Particolare di un Modello di Regressione\n\n### Dal confronto diretto di due medie alla variabile dummy\n\nTradizionalmente, se abbiamo due gruppi indipendenti (ad esempio, bambini con madri che hanno completato la scuola superiore e bambini con madri che non l’hanno completata), per confrontare i loro punteggi medi (ad esempio il QI), usiamo un test t per due campioni indipendenti. Questo test verifica l’ipotesi nulla secondo cui le due medie di popolazione sono uguali.\n\nTuttavia, lo stesso problema può essere formulato come un modello di regressione lineare semplice, in cui la variabile esplicativa è una variabile dummy $D$. Definiamo:\n\n$$\nD_i = \\begin{cases}\n0 & \\text{se l’osservazione } i \\text{ appartiene al gruppo di riferimento (gruppo 0)}, \\\\\n1 & \\text{se l’osservazione } i \\text{ appartiene al gruppo di confronto (gruppo 1)}.\n\\end{cases}\n$$\n\nIl modello di regressione lineare diventa:\n\n$$\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i,\n$$\n\ndove:\n\n- $y_i$ è la variabile risposta per l’osservazione $i$ (nel nostro esempio, il punteggio QI del bambino),\n- $\\alpha$ è l’intercetta, interpretata come la media del gruppo 0,\n- $\\gamma$ è il coefficiente associato a $D_i$, e rappresenta la differenza di media tra il gruppo 1 e il gruppo 0,\n- $\\varepsilon_i$ è il termine di errore, assunto normalmente distribuito con media zero e varianza costante $\\sigma^2$.\n\nQuesto modello stima simultaneamente la media del gruppo di riferimento (tramite $\\alpha$) e la differenza tra i due gruppi (tramite $\\gamma$). Se $\\gamma$ è significativamente diverso da zero, ciò indica che c’è evidenza statistica di una differenza tra le due medie.\n\nIn sintesi:\n\n- Media del gruppo 0: $\\mathbb{E}[y|D=0] = \\alpha$.\n- Media del gruppo 1: $\\mathbb{E}[y|D=1] = \\alpha + \\gamma$.\n- Differenza tra i due gruppi: $\\gamma = \\mathbb{E}[y|D=1] - \\mathbb{E}[y|D=0]$.\n\n### Equivalenza con il test t per due campioni indipendenti\n\nIl test t per due campioni indipendenti, nella sua formulazione classica, verifica l’ipotesi nulla $H_0: \\mu_1 = \\mu_0$, equivalentemente $H_0: \\mu_1 - \\mu_0 = 0$. Nel modello di regressione, questa ipotesi si traduce in $H_0: \\gamma = 0$. \n\nIl test t classico e il test sulla significatività del coefficiente $\\gamma$ nel modello di regressione forniscono gli stessi risultati. Ciò accade sotto le classiche assunzioni del test t (distribuzione normale dell’errore, uguale varianza nei due gruppi, indipendenza delle osservazioni). In definitiva, il test $t$ è un caso speciale del test $F$ associato al modello lineare, ridotto a un singolo predittore. Questo mostra la totale equivalenza tra i due approcci, frequentista-classico.\n\n---\n\n## Un Esempio Illustrativo con R\n\nPer chiarire il concetto, consideriamo un dataset fittizio o già disponibile. Nel nostro esempio utilizziamo lo stesso dataset precedentemente citato: `kidiq`, che contiene i punteggi di QI dei bambini (`kid_score`) e un indicatore dell’istruzione della madre (`mom_hs`), con 1 se la madre ha completato la scuola superiore e 0 altrimenti.\n\n### Caricamento e ispezione dei dati\n\nAssumiamo di avere i dati in un data frame `kidiq`. Diamo un’occhiata alle prime righe:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq <- rio::import(here::here(\"data\", \"kidiq.dta\"))\nhead(kidiq)\n#>   kid_score mom_hs mom_iq mom_work mom_age\n#> 1        65      1  121.1        4      27\n#> 2        98      1   89.4        4      25\n#> 3        85      1  115.4        4      27\n#> 4        83      1   99.4        3      25\n#> 5       115      1   92.7        4      27\n#> 6        98      0  107.9        1      18\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npsych::describe(kidiq)\n#>           vars   n   mean    sd median trimmed   mad min max range  skew\n#> kid_score    1 434  86.80 20.41   90.0   87.93 19.27  20 144 124.0 -0.46\n#> mom_hs       2 434   0.79  0.41    1.0    0.86  0.00   0   1   1.0 -1.39\n#> mom_iq       3 434 100.00 15.00   97.9   99.11 15.89  71 139  67.9  0.47\n#> mom_work     4 434   2.90  1.18    3.0    2.99  1.48   1   4   3.0 -0.45\n#> mom_age      5 434  22.79  2.70   23.0   22.71  2.97  17  29  12.0  0.18\n#>           kurtosis   se\n#> kid_score    -0.19 0.98\n#> mom_hs       -0.07 0.02\n#> mom_iq       -0.59 0.72\n#> mom_work     -1.39 0.06\n#> mom_age      -0.65 0.13\n```\n:::\n\n\n\n\n\nAnalizziamo la numerosità dei due gruppi:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq %>% \n  group_by(mom_hs) %>%\n  summarize(n = n())\n#> # A tibble: 2 × 2\n#>   mom_hs     n\n#>    <dbl> <int>\n#> 1      0    93\n#> 2      1   341\n```\n:::\n\n\n\n\n\nCalcoliamo la media e la deviazione standard del punteggio QI per ciascun gruppo:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_stats <- kidiq %>%\n  group_by(mom_hs) %>%\n  summarise(\n    mean_kid_score = mean(kid_score, na.rm = TRUE),\n    sd_kid_score = sd(kid_score, na.rm = TRUE)\n  )\nsummary_stats\n#> # A tibble: 2 × 3\n#>   mom_hs mean_kid_score sd_kid_score\n#>    <dbl>          <dbl>        <dbl>\n#> 1      0           77.5         22.6\n#> 2      1           89.3         19.0\n```\n:::\n\n\n\n\n\nLa differenza tra le due medie può essere calcolata direttamente:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff_means <- mean(kidiq$kid_score[kidiq$mom_hs == 1]) - \n               mean(kidiq$kid_score[kidiq$mom_hs == 0])\ndiff_means\n#> [1] 11.8\n```\n:::\n\n\n\n\n\nPer visualizzare le distribuzioni dei due gruppi, possiamo usare un grafico, ad esempio un boxplot o un violin plot:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE) + \n  labs(\n    x = \"Istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI per livello d'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))\n```\n\n::: {.cell-output-display}\n![](05_two_means_files/figure-html/unnamed-chunk-7-1.png){width=576}\n:::\n:::\n\n\n\n\n\n### Stima con il Modello di Regressione\n\nApplichiamo ora un modello lineare per stimare la differenza tra i gruppi:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfm <- lm(kid_score ~ mom_hs, data = kidiq)\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_hs, data = kidiq)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -57.55 -13.32   2.68  14.68  58.45 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)    77.55       2.06   37.67   <2e-16 ***\n#> mom_hs         11.77       2.32    5.07    6e-07 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 19.9 on 432 degrees of freedom\n#> Multiple R-squared:  0.0561,\tAdjusted R-squared:  0.0539 \n#> F-statistic: 25.7 on 1 and 432 DF,  p-value: 5.96e-07\n```\n:::\n\n\n\n\n\nIl coefficiente di `mom_hs` ci fornisce la stima della differenza di media tra i due gruppi. L’intercetta rappresenta la media del gruppo con `mom_hs = 0`, mentre l’aggiunta del coefficiente di `mom_hs` alla intercetta ci dà la media del gruppo con `mom_hs = 1`.\n\nSe il valore p associato al coefficiente `mom_hs` è inferiore alla soglia convenzionale (ad esempio 0.05), possiamo concludere che esiste evidenza statistica di una differenza tra le due medie.\n\n### Confronto con il Test t\n\nEffettuiamo anche il test t per confrontare direttamente i due gruppi:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(kid_score ~ mom_hs, data = kidiq)\n#> \n#> \tWelch Two Sample t-test\n#> \n#> data:  kid_score by mom_hs\n#> t = -5, df = 130, p-value = 1e-05\n#> alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n#> 95 percent confidence interval:\n#>  -16.83  -6.71\n#> sample estimates:\n#> mean in group 0 mean in group 1 \n#>            77.5            89.3\n```\n:::\n\n\n\n\n\nL’output del test t includerà:\n\n- La statistica t,\n- Il grado di libertà,\n- Il p-value,\n- Gli intervalli di confidenza della differenza tra le due medie.\n\nIl risultato del test t coincide con l’analisi del modello di regressione: la statistica test del test $t$ di Student è identica al test $t$ della verifica dell'ipotesi nulla $H_0: \\beta = 0$ per il coefficiente di regressione di `mom_hs` del modello lineare.\n\n---\n\n## Perché Utilizzare il Modello di Regressione?\n\nSe l’obiettivo è solo confrontare due medie, il test t rimane il metodo più semplice e diretto. Tuttavia, la reinterpretazione del test t come caso particolare di un modello di regressione offre diversi vantaggi:\n\n1. **Flessibilità**: Se vogliamo aggiungere una seconda variabile esplicativa (ad esempio, l’età del bambino o il livello di istruzione del padre), il modello di regressione ci consente facilmente di estendere l’analisi. Il test t, focalizzato su due gruppi, non si generalizza altrettanto facilmente.\n\n2. **Un approccio unificante**: Molte analisi statistiche possono essere ricondotte a modelli lineari. Imparando a vedere il test t come un modello di regressione, gettiamo le basi per approcci più complessi (ANOVA, regressione multipla, modelli lineari generalizzati).\n\n3. **Controllo di Covariate**: Se sospettiamo che alcune variabili di confondimento possano influenzare le differenze tra i gruppi, possiamo includerle come predittori nel modello di regressione e controllarne l’effetto. Questo non è possibile con un semplice test t.\n\n---\n\n## Considerazioni Finali\n\nIn questo capitolo abbiamo mostrato come il test t per due campioni indipendenti possa essere interpretato come un caso particolare di un modello di regressione lineare con variabile dummy. Adottando l’approccio frequentista classico tramite la funzione `lm()` in R, possiamo:\n\n- Stimare la differenza di media tra due gruppi come coefficiente di un modello lineare.\n- Testare l’ipotesi di uguaglianza delle medie equivalendo il test sul coefficiente a un test t.\n- Estendere facilmente l’analisi ad altri predittori e confrontare contemporaneamente più gruppi, covariate e interazioni.\n\nQuesta prospettiva unificante apre la strada a un utilizzo più ampio dei modelli lineari e a un approccio integrato all’analisi dei dati. Pur non abbandonando mai l’intuizione del confronto di due medie, l’uso della regressione lineare fornisce un linguaggio e una struttura che saranno fondamentali per affrontare problemi statistici più complessi.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] viridis_0.6.5     viridisLite_0.4.2 gridExtra_2.3     patchwork_1.3.0  \n#>  [5] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#>  [9] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [13] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#> [17] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#> [21] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#>  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#>  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0      \n#> [13] rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3    fansi_1.0.6      \n#> [17] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       R.methodsS3_1.8.2\n#> [21] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#> [25] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#> [29] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#> [33] pillar_1.9.0      gtable_0.3.6      glue_1.8.0        haven_2.5.4      \n#> [37] xfun_0.49         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#> [41] nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2\n```\n:::\n\n\n\n\n\n## Bibliografia {.unnumbered}\n\n",
    "supporting": [
      "05_two_means_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}