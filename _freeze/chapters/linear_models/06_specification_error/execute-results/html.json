{
  "hash": "947eaa9b209724b2ee4eed3be0f6f14f",
  "result": {
    "engine": "knitr",
    "markdown": "# Errore di specificazione\n\n\n**Prerequisiti**\n\n- Leggi [Statistical model specification](https://en.wikipedia.org/wiki/Statistical_model_specification).\n\n**Concetti e competenze chiave**\n\n::: callout-important\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr)\n```\n:::\n\n\n\n:::\n\n## Introduzione \n\nIn questo capitolo esamineremo l'errore di specificazione nei modelli di regressione lineare. L'errore di specificazione si verifica quando una variabile importante viene omessa dal modello, causando stime dei coefficienti che risultano sistematicamente distorte e inconsistenti.\n\n### Dimostrazione\n\nLa dimostrazione algebrica dell'errore di specificazione nel modello di regressione, in caso di omissione di una variabile rilevante, coinvolge l'analisi delle conseguenze che questa omissione ha sulla stima dei coefficienti di regressione. \n\nQuando un modello di regressione omette una variabile rilevante che è correlata sia con la variabile dipendente $Y$ sia con almeno una delle variabili indipendenti incluse nel modello, il coefficiente stimato per le variabili indipendenti incluse può essere sistematicamente distorto. \n\nPer comprendere il bias causato dall'omissione di una variabile rilevante in un modello di regressione, è essenziale analizzare dettagliatamente il calcolo delle covarianze e varianze coinvolte. Di seguito viene fornita una spiegazione dei passaggi algebrici che portano alla formulazione del *bias di omissione variabile* [*Omitted Variable Bias*, OVB; per un approfondimento, si veda @caudek2001statistica].\n\n### Modello Completo e Modello Ridotto\n\n1. **Modello Completo:**\n\n   $$\n   Y = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon\n   $$\n\n   Qui, $Y$ è la variabile dipendente, $X$ e $Z$ sono variabili indipendenti, $\\beta_0, \\beta_1, \\beta_2$ sono i coefficienti, e $\\epsilon$ è il termine di errore.\n\n2. **Modello Ridotto (con omissione di $Z$):**\n\n   $$\n   Y = \\alpha_0 + \\alpha_1 X + u\n   $$\n\n   dove $u = \\beta_2 Z + \\epsilon$ rappresenta il nuovo termine di errore che ora include l'effetto non osservato di $Z$.\n\n### Decomposizione di $X$\n\nIpotesi:\n\n$$ X = \\gamma_0 + \\gamma_1 Z + V $$\n\ndove $V$ è una parte di $X$ indipendente da $Z$, quindi $\\text{Cov}(V, Z) = 0$.\n\n### Sostituzione nel Modello Ridotto\n\nSostituendo la decomposizione di $X$ nel modello ridotto, otteniamo:\n\n$$ Y = \\alpha_0 + \\alpha_1 (\\gamma_0 + \\gamma_1 Z + V) + u $$\n\n$$ Y = \\alpha_0 + \\alpha_1 \\gamma_0 + \\alpha_1 \\gamma_1 Z + \\alpha_1 V + \\beta_2 Z + \\epsilon $$\n\n$$ Y = (\\alpha_0 + \\alpha_1 \\gamma_0) + (\\alpha_1 \\gamma_1 + \\beta_2) Z + \\alpha_1 V + \\epsilon $$\n\n### Calcolo della Covarianza $\\text{Cov}(Y, X)$\n\n$$ \\text{Cov}(Y, X) = \\text{Cov}(\\beta_1 X + \\beta_2 Z + \\epsilon, X) $$\n\n$$ \\text{Cov}(Y, X) = \\beta_1 \\text{Var}(X) + \\beta_2 \\text{Cov}(Z, X) $$\n\ndove si usa che $\\text{Cov}(\\epsilon, X) = 0$ poiché $\\epsilon$ è indipendente da $X$.\n\n### Calcolo della Varianza di $X$\n\n$$ \\text{Var}(X) = \\text{Var}(\\gamma_0 + \\gamma_1 Z + V) $$\n\n$$ \\text{Var}(X) = \\gamma_1^2 \\text{Var}(Z) + \\text{Var}(V) $$\n\nAncora, $\\text{Cov}(Z, V) = 0$ perché $V$ è definito come indipendente da $Z$.\n\n### Formula del Coefficiente Stimato $\\hat{\\alpha}_1$\n\n$$ \\hat{\\alpha}_1 = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} $$\n\n$$ \\hat{\\alpha}_1 = \\beta_1 + \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} $$\n\n### Interpretazione del Bias\n\nIl bias nel coefficiente stimato $\\alpha_1$, rispetto al vero coefficiente $\\beta_1$, è dato da:\n\n$$ \\text{Bias}(\\hat{\\alpha}_1) = \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} $$\n\nQuesto risultato dimostra che il bias è direttamente proporzionale al coefficiente $\\beta_2$ della variabile omessa $Z$ e al rapporto di covarianza tra $Z$ e $X$ diviso per la varianza di $X$. Questo bias può essere positivo o negativo a seconda della direzione della correlazione tra $X$ e $Z$, e della grandezza di $\\beta_2$.\n\nIn sintesi, l'omissione di $Z$ introduce un bias nella stima di $\\alpha_1$ che non riflette accuratamente $\\beta_1$ se $Z$ è correlata sia con $Y$ che con $X$. Questo errore di specificazione può portare a conclusioni errate sull'effetto di $X$ su $Y$ e compromettere l'accuratezza delle inferenze tratte dal modello di regressione.\n\n## Un esempio numerico \n\nConsideriamo il problema di analizzare l'impatto di due variabili indipendenti, **motivazione** e **ansia**, sulla **prestazione** in un compito specifico. Supponiamo che:\n- L'**ansia** influenzi negativamente la prestazione.\n- La **motivazione** influenzi positivamente la prestazione.\n\nQuesto esempio illustra come un errore di specificazione del modello, ossia l'omissione di una variabile rilevante, possa portare a stime distorte e a conclusioni fuorvianti.\n\n---\n\n### Scenari distinti\n\n1. **Modello Completo**:  \n   Quando includiamo **sia la motivazione che l'ansia** nel modello di regressione, il coefficiente stimato per l'ansia è negativo, riflettendo correttamente il suo impatto sfavorevole sulla prestazione. Questo dimostra che, in presenza di tutte le variabili rilevanti, il modello fornisce stime accurate e non distorte.\n\n2. **Modello Ridotto (omissione della motivazione)**:  \n   Se omettiamo la motivazione, che è positivamente correlata sia con la prestazione sia con l'ansia, il coefficiente stimato per l'ansia può risultare positivo, suggerendo erroneamente che l'ansia abbia un effetto benefico sulla prestazione. Questo fenomeno si verifica a causa dell'effetto indiretto della motivazione, che non viene controllato nel modello. In pratica, la correlazione tra motivazione e ansia \"maschera\" l'effetto negativo dell'ansia sulla prestazione.\n\n---\n\n### Generazione dei dati\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generazione di dati casuali\nset.seed(42)\nn <- 100  # Numero di osservazioni\n\n# Variabili indipendenti con correlazione positiva tra loro\nmotivazione <- rnorm(n, mean = 100, sd = 10)\nansia <- 200 + 0.75 * motivazione + rnorm(n, mean = 0, sd = 5)\n\n# Variabile dipendente con peso maggiore sulla motivazione rispetto all'ansia\nprestazione <- 5 * motivazione - 1 * ansia + rnorm(n, mean = 0, sd = 50)\n\n# Creazione del data frame\ndata <- data.frame(\n  Motivazione = motivazione,\n  Ansia = ansia,\n  Prestazione = prestazione\n)\n```\n:::\n\n\n\n\n---\n\n### Modello di regressione completo\n\nNel modello completo, entrambe le variabili indipendenti, **motivazione** e **ansia**, sono incluse:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modello completo con Motivazione e Ansia\nmodel_full <- lm(Prestazione ~ Motivazione + Ansia, data = data)\n\n# Stima dei coefficienti\nsummary(model_full)$coefficients\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)  -98.643     228.80  -0.431 0.667334\n#> Motivazione    3.642       0.99   3.678 0.000385\n#> Ansia         -0.147       1.13  -0.130 0.896468\n```\n:::\n\n\n\n\nInterpretazione dei risultati:  \n\n- Il coefficiente per la motivazione ($\\beta_{\\text{motivazione}}$) è positivo, indicando che un aumento della motivazione è associato a un miglioramento delle prestazioni.\n- Il coefficiente per l'ansia ($\\beta_{\\text{ansia}}$) è negativo, riflettendo il suo effetto sfavorevole sulla prestazione.\n\n---\n\n### Modello ridotto (omissione della motivazione)\n\nNel modello ridotto, includiamo solo l'**ansia** come predittore:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modello ridotto con solo Ansia\nmodel_ansia_only <- lm(Prestazione ~ Ansia, data = data)\n\n# Stima dei coefficienti\nsummary(model_ansia_only)$coefficients\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)  -723.99    162.631   -4.45 2.26e-05\n#> Ansia           3.46      0.591    5.85 6.61e-08\n```\n:::\n\n\n\n\nInterpretazione dei risultati:  \n- Il coefficiente per l'ansia nel modello ridotto può cambiare segno, risultando positivo. Questo suggerirebbe erroneamente che l'ansia migliora la prestazione.  \n- Questo effetto distorto è dovuto all'omissione della motivazione, che è correlata sia con l'ansia sia con la prestazione.\n\n---\n\n### Confronto tra i modelli\n\n| Modello             | Coefficiente per l'Ansia | Coefficiente per la Motivazione |\n|---------------------|--------------------------|---------------------------------|\n| Modello Completo    | Negativo                 | Positivo                       |\n| Modello Ridotto     | Positivo (distorto)      | Non incluso                    |\n\n---\n\nQuesto esempio dimostra l'importanza di includere tutte le variabili rilevanti in un modello di regressione:\n\n1. L'omissione di una variabile rilevante, come la motivazione, che è correlata sia con la variabile dipendente sia con un altro predittore, porta a stime distorte dei coefficienti.\n2. In questo caso, l'effetto negativo dell'ansia sulla prestazione viene mascherato nel modello ridotto, portando a una conclusione errata sul suo ruolo.\n\n### Considerazioni sull’errore di specificazione\n\nL’errore di specificazione si verifica quando una variabile rilevante viene omessa o quando una variabile non rilevante viene inclusa. Nel caso di omissione:\n\n- La stima del coefficiente associato alle variabili incluse può essere distorta, riflettendo indirettamente l'effetto della variabile omessa.  \n- Questo problema è noto come **bias da confondimento** e può essere evitato solo attraverso una corretta specificazione del modello, basata su una solida comprensione teorica delle relazioni tra le variabili.\n\nIn conclusione, l'analisi dei dati deve essere accompagnata da un'attenta riflessione teorica per garantire che le stime dei coefficienti di regressione riflettano accuratamente le relazioni tra le variabili e supportino inferenze valide.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] viridis_0.6.5     viridisLite_0.4.2 gridExtra_2.3     patchwork_1.3.0  \n#>  [5] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#>  [9] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [13] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#> [17] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#> [21] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#>  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#>  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#> [13] jsonlite_1.8.9    fansi_1.0.6       mnormt_2.1.1      cli_3.6.3        \n#> [17] rlang_1.1.4       munsell_0.5.1     withr_3.0.2       tools_4.4.2      \n#> [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#> [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#> [29] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.6      glue_1.8.0       \n#> [33] xfun_0.49         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#> [37] nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2\n```\n:::\n\n\n\n\n## Bibliografia {.unnumbered}\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}