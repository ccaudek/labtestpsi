{
  "hash": "29b72da400814ca6e99390d3edf4ac61",
  "result": {
    "engine": "knitr",
    "markdown": "# Il modello di regressione multipla\n\n\n::: callout-note\n## In questo capitolo imparerai a\n\n- \n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere *Regression and Other Stories* [@gelman2020regression].\n  - Concentrarsi sul capitolo 10 \"Linear regression with multiple predictors\" che fornisce una guida dettagliata al modello di regressione multipla.\n:::\n\n::: callout-important\n## Preparazione del Notebook\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr)\n```\n:::\n\n\n\n\n:::\n\n## Introduzione \n\nIn questo capitolo introdurremo il modello di regressione multipla mostrando come possa essere implementato in R. Ci concentreremo sull'interpretazione dei coefficienti parziali di regressione.\n\n## Regressione multipla\n\nLa regressione multipla rappresenta un'estensione del modello di regressione semplice, e permette di esplorare e quantificare le relazioni tra una variabile dipendente e più variabili indipendenti. \n\nUn modello lineare univariato può essere descritto, in forma matriciale, come\n\n$$ \n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \n$$ {#eq-mult-reg-model}\n\ndove $\\mathbf{y} \\in \\mathbb{R}^n$ è il vettore delle variabili di risposta, $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ è la matrice delle costanti note, $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ è il vettore dei parametri sconosciuti, e $\\boldsymbol{\\epsilon} \\in \\mathbb{R}^n$ è il vettore degli errori casuali non osservabili. Espanso in forma completa, il modello dell'@eq-mult-reg-model può essere espresso come\n\n$$\n\\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{pmatrix},\n$$ {#eq-mult-reg-model-matrix}\n\ndove la prima colonna di $\\mathbf{X}$ è spesso un vettore di uno, denotato $\\mathbf{1}_n$. Il modello dell'@eq-mult-reg-model-matrix esprime ciascuna delle $n$ osservazioni in $\\mathbf{y}$ come una combinazione lineare dei parametri sconosciuti in $\\boldsymbol{\\beta}$ con coefficienti da $\\mathbf{X}$, cioè,\n\n$$ \ny_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta} + \\epsilon_i = \\sum_{j=1}^p x_{ij} \\beta_j + \\epsilon_i, \n$$\n\nper $i = 1, \\ldots, n$, dove $\\mathbf{x}_i \\in \\mathbb{R}^p$ è l'ennesima riga di $\\mathbf{X}$. \n\n## Interpretazione\n\nPassando dal modello semplice $y = a + bx + \\text{errore}$ al modello più generale $y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{errore}$, emergono nuove complessità. Queste includono le decisioni su quali predittori $x$ includere nel modello, l'interpretazione dei coefficienti e delle loro interazioni, e la costruzione di nuovi predittori a partire dalle variabili esistenti per catturare elementi di discrezionalità e non linearità. \n\nI coefficienti di regressione, in un contesto di regressione multipla, sono tipicamente più complicati da interpretare rispetto a quelli di un modello con un solo predittore. L'interpretazione di un dato coefficiente, infatti, è parzialmente condizionata dalle altre variabili presenti nel modello. Il coefficiente $\\beta_k$ rappresenta la differenza media o attesa nella variabile risposta $y$, confrontando due individui che differiscono di un'unità nel predittore $x_k$ ma sono identici per quanto riguarda gli altri predittori. Questo concetto è talvolta sintetizzato con l'espressione \"confrontare due osservazionni (o persone) che differiscono per $x_k$ a parità delle altre variabili\".\n\nDal punto di vista dell'implementazione con Stan, l'estensione del modello per includere molteplici predittori dell'intelligenza del bambino è relativamente semplice. È necessario costruire una matrice $X$ contenente le colonne che rappresentano i vari predittori che intendiamo analizzare. Per l'esempio specifico in questione, i predittori selezionati per l'intelligenza del bambino includono: la scolarità della madre (codificata come 0 o 1 a seconda che la madre abbia completato o meno le scuole superiori), l'intelligenza della madre e l'età della madre. Prima di procedere con l'analisi, è importante standardizzare tutte queste variabili per facilitare l'interpretazione dei risultati e migliorare la stabilità numerica del modello.\n\n## Un esempio pratico\n\nPer fare un esempio pratico, analizzeremo nuovamente i dati sull'intelligenza di un gruppo di bambini. In questo caso, cercheremo di predire l'intelligenza media dei bambini considerando tre fattori: se le madri hanno completato la scuola superiore, l'intelligenza della madre e l'età della madre.\n\nImportiamo i dati:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkidiq <- rio::import(\n  here::here(\"data\", \"kidiq.dta\")\n)\nglimpse(kidiq)\n#> Rows: 434\n#> Columns: 5\n#> $ kid_score <dbl> 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78…\n#> $ mom_hs    <dbl> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, …\n#> $ mom_iq    <dbl> 121.1, 89.4, 115.4, 99.4, 92.7, 107.9, 138.9, 125.1, 81.6…\n#> $ mom_work  <dbl> 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, …\n#> $ mom_age   <dbl> 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 2…\n```\n:::\n\n\n\n\n\n- `kid_score`: punteggio di intelligenza del bambino (variabile dipendente).\n- `mom_hs`: se la madre ha completato la scuola superiore (1 = sì, 0 = no).\n- `mom_iq`: intelligenza della madre.\n- `mom_age`: età della madre.\n\nPer riscrivere la sezione relativa al modello di regressione multipla utilizzando l'approccio frequentista con `lm()` in R, procedo a chiarire e adattare il contenuto includendo i dettagli rilevanti per un approccio basato sulla massima verosimiglianza e non sul metodo bayesiano.\n\n## Regressione Multipla con `lm()`\n\nCon R, l'implementazione è semplice utilizzando la funzione `lm()`. Di seguito forniamo un esempio basato sui dati di intelligenza del bambino utilizzati nel file.\n\n### Modello di regressione multipla\n\nPer stimare l'effetto dei predittori sul punteggio del bambino:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modello di regressione multipla\nmodel <- lm(kid_score ~ mom_hs + mom_iq + mom_age, data = kidiq)\n\n# Risultati del modello\nsummary(model)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_hs + mom_iq + mom_age, data = kidiq)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#>  -53.3  -12.4    2.4   11.2   50.2 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  20.9847     9.1301    2.30    0.022 *  \n#> mom_hs        5.6472     2.2577    2.50    0.013 *  \n#> mom_iq        0.5625     0.0606    9.28   <2e-16 ***\n#> mom_age       0.2248     0.3307    0.68    0.497    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.1 on 430 degrees of freedom\n#> Multiple R-squared:  0.215,\tAdjusted R-squared:  0.21 \n#> F-statistic: 39.3 on 3 and 430 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\n\nIl modello stimato ha la seguente formula:\n\n$$\n\\text{kid\\_score} = 20.98 + 5.65 \\cdot \\text{mom\\_hs} + 0.56 \\cdot \\text{mom\\_iq} + 0.22 \\cdot \\text{mom\\_age} + \\varepsilon\n$$\n\n### Risultati\n\n- **Intercetta** (`Intercept`): $20.98$  \n  Questo valore rappresenta il punteggio medio del bambino quando tutte le variabili predittive (`mom_hs`, `mom_iq`, `mom_age`) assumono valore zero. Sebbene non abbia un significato pratico, dato che un'età della madre pari a zero non è realistica, l'intercetta funge da punto di riferimento matematico nel modello.\n\n- **`mom_hs` ($5.65$, errore standard $2.26$)**:  \n  Il coefficiente indica che, a parità di QI e età della madre, i bambini le cui madri hanno completato la scuola superiore ottengono un punteggio medio di $5.65$ punti superiore rispetto ai bambini le cui madri non lo hanno fatto. Il rapporto tra la stima del coefficiente e il suo errore standard ($5.65 / 2.26 \\approx 2.50$) supera la soglia di 2, suggerendo che i dati contengono informazioni sufficienti per supportare questa relazione.\n\n- **`mom_iq` ($0.56$, errore standard $0.06$)**:  \n  Per ogni punto in più nel QI della madre, il punteggio medio del bambino aumenta di $0.56$, a parità di istruzione ed età della madre. Il rapporto tra stima ed errore standard ($0.56 / 0.06 = 9.28$) è molto elevato, indicando un rapporto segnale-rumore significativo che conferma la robustezza dell'evidenza fornita dai dati.\n\n- **`mom_age` ($0.22$, errore standard $0.33$)**:  \n  Per ogni anno in più di età della madre, il punteggio medio del bambino aumenta di $0.22$, a parità di QI e istruzione della madre. Tuttavia, il rapporto tra stima ed errore standard ($0.22 / 0.33 \\approx 0.68$) è ben al di sotto della soglia di 2. Questo indica che i dati non forniscono informazioni sufficienti per una stima affidabile di questa relazione.\n\nIn questo modello, i coefficienti associati a `mom_hs` e `mom_iq` presentano rapporti segnale-rumore adeguati, mentre quello associato a `mom_age` non soddisfa questa condizione.\n\n### Indicatori di Diagnostica del Modello\n\n- **Residual standard error (Errore standard dei residui)**: $18.1$  \n  La deviazione standard dei residui indica l'errore medio commesso dal modello nel predire i punteggi del bambino.\n\n- **R-squared (R²)**: $0.215$  \n  Il modello spiega circa il $21.5\\%$ della variabilità totale del punteggio del bambino. Questo indica che i predittori inclusi non spiegano completamente il fenomeno.\n\n- **Adjusted R-squared**: $0.21$  \n  Dopo aver corretto per il numero di predittori nel modello, il $21.0\\%$ della variabilità del punteggio è spiegata dalle variabili indipendenti.\n\n- **F-statistic**: $39.3$  \n  Il test F è altamente significativo ($p < 2 \\cdot 10^{-16}$), suggerendo che il modello complessivo (con tutti i predittori inclusi) è migliore di un modello senza predittori.\n\n### Residui\n\n- **Distribuzione dei residui**:  \n  I residui vanno da $-53.3$ a $50.2$, con una mediana di $2.4$. La loro distribuzione dovrebbe essere verificata per accertarsi che segua approssimativamente una distribuzione normale e che non vi siano pattern particolari.\n\n## Visualizzazione\n\nÈ possibile visualizzare la relazione tra i predittori e la variabile dipendente con i seguenti comandi in R:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE)\n#> `geom_smooth()` using formula = 'y ~ x'\n```\n\n::: {.cell-output-display}\n![](09_stan_multreg_files/figure-html/unnamed-chunk-4-1.png){width=576}\n:::\n:::\n\n\n\n\n\n\n## Standardizzazione dei predittori\n\nLa standardizzazione dei predittori consiste nel trasformare ciascuna variabile predittiva in una scala con media 0 e deviazione standard 1. Questo processo consente di confrontare direttamente i coefficienti β del modello, poiché dopo la standardizzazione ogni coefficiente rappresenta l'effetto di un incremento di una deviazione standard nella variabile predittiva sulla variabile dipendente, espressa anch’essa in unità di deviazioni standard.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standardizzazione delle variabili\nkid_data_scaled <- as.data.frame(scale(kidiq))\n\n# Modello con variabili standardizzate\nmodel_scaled <- lm(\n  kid_score ~ mom_hs + mom_iq + mom_age, data = kid_data_scaled\n)\n\n# Risultati del modello standardizzato\nsummary(model_scaled)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_hs + mom_iq + mom_age, data = kid_data_scaled)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -2.611 -0.609  0.117  0.550  2.458 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -2.85e-15   4.27e-02    0.00    1.000    \n#> mom_hs       1.14e-01   4.54e-02    2.50    0.013 *  \n#> mom_iq       4.13e-01   4.46e-02    9.28   <2e-16 ***\n#> mom_age      2.97e-02   4.38e-02    0.68    0.497    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.889 on 430 degrees of freedom\n#> Multiple R-squared:  0.215,\tAdjusted R-squared:  0.21 \n#> F-statistic: 39.3 on 3 and 430 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\n\n### Standardizzazione dei Predittori\n\nLa standardizzazione dei predittori consiste nel trasformare ciascuna variabile predittiva in una scala con media 0 e deviazione standard 1. Questo processo consente di confrontare direttamente i coefficienti $\\beta$ del modello, poiché dopo la standardizzazione ogni coefficiente rappresenta l'effetto di un incremento di **una deviazione standard** nella variabile predittiva sulla variabile dipendente, espressa anch’essa in unità di deviazioni standard.\n\nIl codice per standardizzare i predittori e stimare il modello standardizzato è:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standardizzazione delle variabili\nkid_data_scaled <- as.data.frame(scale(kidiq))\n\n# Modello con variabili standardizzate\nmodel_scaled <- lm(\n  kid_score ~ mom_hs + mom_iq + mom_age, data = kid_data_scaled\n)\n\n# Risultati del modello standardizzato\nsummary(model_scaled)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_hs + mom_iq + mom_age, data = kid_data_scaled)\n#> \n#> Residuals:\n#>    Min     1Q Median     3Q    Max \n#> -2.611 -0.609  0.117  0.550  2.458 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -2.85e-15   4.27e-02    0.00    1.000    \n#> mom_hs       1.14e-01   4.54e-02    2.50    0.013 *  \n#> mom_iq       4.13e-01   4.46e-02    9.28   <2e-16 ***\n#> mom_age      2.97e-02   4.38e-02    0.68    0.497    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.889 on 430 degrees of freedom\n#> Multiple R-squared:  0.215,\tAdjusted R-squared:  0.21 \n#> F-statistic: 39.3 on 3 and 430 DF,  p-value: <2e-16\n```\n:::\n\n\n\n\n\n- **Intercetta** ($-2.85 \\cdot 10^{-15}$):  \n  L'intercetta è molto vicina a zero poiché, dopo la standardizzazione, tutte le variabili predittive hanno media 0. Non ha significato interpretativo in un modello standardizzato.\n\n- **`mom_hs` ($0.11$, errore standard $0.045$)**:  \n  Il coefficiente indica che, a parità di altre variabili, i bambini le cui madri hanno completato la scuola superiore ottengono, in media, un punteggio di $0.11$ deviazioni standard più alto rispetto a quelli le cui madri non lo hanno fatto. Il rapporto stima/errore standard ($0.11 / 0.045 \\approx 2.50$) supera la soglia di 2, suggerendo che i dati forniscono un segnale sufficiente per sostenere questo effetto.\n\n- **`mom_iq` ($0.41$, errore standard $0.045$)**:  \n  Questo coefficiente indica che, per ogni incremento di una deviazione standard nel QI della madre, il punteggio del bambino aumenta, in media, di $0.41$ deviazioni standard, a parità di altre variabili. Il rapporto stima/errore standard ($0.41 / 0.045 \\approx 9.28$) è elevato, indicando un segnale molto forte nei dati.\n\n- **`mom_age` ($0.03$, errore standard $0.044$)**:  \n  Per ogni incremento di una deviazione standard nell'età della madre, il punteggio del bambino aumenta, in media, di $0.03$ deviazioni standard. Tuttavia, il rapporto stima/errore standard ($0.03 / 0.044 \\approx 0.68$) è ben al di sotto di 2, suggerendo che i dati non forniscono informazioni sufficienti per sostenere una relazione tra l'età della madre e il punteggio del bambino.\n\nDopo la standardizzazione, i coefficienti forniscono un'indicazione chiara dell'importanza relativa dei predittori nel modello. In questo caso:\n\n- **`mom_iq` ($0.41$)** ha l'effetto più forte sulla variabile dipendente, indicando che il QI della madre è il predittore più influente per il punteggio del bambino.\n- **`mom_hs` ($0.11$)** ha un effetto positivo moderato, ma significativamente inferiore rispetto a quello di `mom_iq`.\n- **`mom_age` ($0.03$)** ha un effetto trascurabile nel contesto del modello.\n\n---\n\n#### Vantaggi della standardizzazione\n\n1. **Confrontabilità tra predittori**: Poiché i predittori sono espressi nella stessa unità (deviazioni standard), i coefficienti standardizzati permettono un confronto diretto dell'importanza relativa di ciascun predittore.\n2. **Interpretazione indipendente dalle unità originali**: La standardizzazione elimina la dipendenza dalle scale originali delle variabili, rendendo l'interpretazione dei coefficienti indipendente dalle unità di misura.\n3. **Facilitazione della comunicazione dei risultati**: I coefficienti standardizzati sono utili in contesti dove è importante comunicare l'importanza relativa dei predittori.\n\nIn conclusione, la standardizzazione è particolarmente utile quando si vuole confrontare direttamente l'importanza relativa dei predittori in un modello. In questo esempio, i dati mostrano chiaramente che il QI della madre ($mom_iq$) ha un effetto molto più forte rispetto all'istruzione ($mom_hs$) o all'età ($mom_age$) della madre sul punteggio del bambino. Tuttavia, come sempre, l'interpretazione causale di questi coefficienti richiede cautela e dipende dalla correttezza delle ipotesi causali sottostanti.\n\n## Controllo degli Assunti\n\nÈ fondamentale controllare gli assunti della regressione lineare:\n\n- **Linearità**: la relazione tra ciascun predittore e la variabile dipendente deve essere lineare.\n- **Indipendenza degli errori**: gli errori devono essere indipendenti tra loro.\n- **Omogeneità della varianza**: la varianza degli errori deve essere costante.\n- **Normalità degli errori**: gli errori devono seguire una distribuzione normale.\n\nPer verificare questi assunti in R:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Verifica degli assunti\npar(mfrow = c(2, 2))\nplot(model)\n```\n\n::: {.cell-output-display}\n![](09_stan_multreg_files/figure-html/unnamed-chunk-7-1.png){width=576}\n:::\n:::\n\n\n\n\n## Il Controllo Statistico\n\nNel contesto della regressione multipla, l'interpretazione dei coefficienti parziali differisce da quella della regressione bivariata. Nel modello bivariato, il coefficiente $\\beta_1$ viene interpretato come il cambiamento atteso in $Y$ per un incremento unitario in $X_1$. Tuttavia, nel modello di regressione multipla, $\\beta_1$ rappresenta il cambiamento atteso in $Y$ per un incremento unitario in $X_1$, **mantenendo costanti gli effetti di tutte le altre variabili** ($X_2, X_3, \\ldots, X_p$). In altre parole, $\\beta_1$ ci dice come varia in media $Y$ quando $X_1$ cambia, considerando anche l'interazione di $X_1$ con le altre variabili e tenendo conto di tali variazioni.\n\nConsideriamo il coefficiente associato all'intelligenza della madre ($\\beta = 0.41$) in un modello che predice l'intelligenza del bambino. Questo coefficiente significa che il punteggio medio di intelligenza del bambino aumenta di 0.41 deviazioni standard per ogni deviazione standard aggiuntiva nell'intelligenza della madre, **a parità di livello di istruzione ed età della madre**. Questo implica che stiamo isolando l'impatto dell'intelligenza della madre in una popolazione in cui livello di istruzione ed età sono omogenei.\n\nMa cosa significa mantenere costanti le altre variabili?\n\nUn esempio classico è la correlazione tra il numero di scarpe e le abilità matematiche. A prima vista, esiste una correlazione positiva tra queste due variabili. Tuttavia, questa relazione è dovuta al fatto che i bambini, con numeri di scarpe più piccoli rispetto agli adulti, hanno generalmente anche abilità matematiche inferiori. Se controlliamo per l'età (considerando solo individui della stessa età), la correlazione tra numero di scarpe e abilità matematiche scompare. In questo caso, l'età agisce come **variabile confondente**, e controllarla significa analizzare la relazione tra numero di scarpe e abilità matematiche come se tutti gli individui avessero la stessa età.\n\nNei modelli di regressione, il controllo degli effetti delle altre variabili viene effettuato attraverso una procedura statistica che simula questa \"condizione ideale\". \n\nEsaminiamo i risultati della seguente simulazione in R.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nn <- 100\nx1 <- rnorm(n)\nx2 <- rnorm(n)\nalpha <- 2\nbeta1 <- 1.5\nbeta2 <- 0.5\ny <- alpha + beta1 * x1 + beta2 * x2 + rnorm(n, 0, 1)\n\ndat <- tibble(x1, x2, y)\n```\n:::\n\n\n\n\n\n1. **Regressione di $Y$ su $X_2$:**  \n   Per rimuovere l'influenza di $X_2$ su $Y$:\n\n\n\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   fm1 <- lm(y ~ x2, data = dat)\n   e_y <- fm1$resid\n   ```\n   :::\n\n\n\n\n\n2. **Regressione di $X_1$ su $X_2$:**  \n   Per rimuovere l'influenza di $X_2$ su $X_1$:\n\n\n\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   fm2 <- lm(x1 ~ x2, data = dat)\n   e_x1 <- fm2$resid\n   ```\n   :::\n\n\n\n\n\n3. **Regressione dei residui di $Y$ sui residui di $X_1$:**  \n   Questo calcola il coefficiente parziale di regressione di $X_1$ su $Y$:\n\n\n\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   fm3 <- lm(e_y ~ e_x1)\n   coef(fm3)\n   #> (Intercept)        e_x1 \n   #>   -5.84e-17    1.52e+00\n   ```\n   :::\n\n\n\n\n\nLa simulazione precedente illustra il significato di controllo statistico e ci consente di capire il significato del concetto di coefficiente parziale di regressione.\n\nIl coefficiente parziale quantifica l'effetto di una variabile esplicativa ($X_j$) sulla variabile dipendente ($Y$), depurando l'effetto di $X_j$ dall'influenza degli altri predittori. In sostanza:\n\n- Misura l'effetto puro di $X_j$ su $Y$, considerando solo la parte di $X_j$ indipendente dai rimanenti predittori.\n- Analizza la relazione tra $Y$ e $X_j$ in un contesto teorico in cui tutti gli individui hanno livelli identici per le altre variabili ($X$).\n\n### Limitazioni\n\nQuesto approccio è limitato alle **relazioni lineari** tra le variabili. Non può catturare effetti non lineari o interazioni più complesse tra i predittori. Tuttavia, fornisce una base solida per isolare e interpretare gli effetti dei predittori in un modello.\n\nIn conclusione, il controllo statistico nel contesto della regressione multipla consente di interpretare in modo chiaro e isolato l'effetto di ciascun predittore sulla variabile dipendente. Questo approccio permette di approssimare condizioni ideali e valutare con maggiore precisione le relazioni tra variabili in contesti complessi.\n\n## Coefficienti Parziali di Regressione e Causalità\n\nÈ fondamentale chiarire che il modello di regressione **non implica automaticamente una relazione causale** tra le variabili. Attribuire ai coefficienti del modello un significato causale è comune, ma spesso errato.\n\nNel modello di regressione, il coefficiente parziale $\\beta_j$ viene spesso interpretato come l'incremento atteso nella variabile dipendente $Y$ per una variazione unitaria della variabile indipendente $X_j$, mantenendo costanti gli effetti lineari delle altre variabili predittive incluse nel modello. Questa interpretazione suggerisce implicitamente una relazione causale: se $X_j$ aumenta di un'unità, la media di $Y$ cambierà di una quantità pari a $\\beta_j$, tenendo conto dell'effetto lineare delle altre variabili [@westreich2013table].\n\nTuttavia, **questa interpretazione è valida solo in condizioni specifiche** che spesso non si verificano nella pratica. Per essere valida, è necessario che:\n\n1. Il modello di regressione rappresenti accuratamente il processo generativo dei dati.\n2. Non vi siano variabili confondenti non incluse nel modello.\n3. Le relazioni tra le variabili siano correttamente specificate (ad esempio, lineari se il modello è lineare).\n4. Non vi siano errori di misura o altre fonti di bias nei dati.\n\nNella maggior parte dei casi, i coefficienti di regressione riflettono semplicemente **relazioni descrittive** osservate nel campione di dati analizzato. La validità di queste relazioni al di fuori del campione (cioè nella popolazione generale) dipende dalla correttezza della specificazione del modello e dalla rappresentatività del campione. Se il modello è mal specificato o se vi sono variabili confondenti escluse, l'interpretazione dei coefficienti come indicazione di relazioni causali diventa altamente problematica.\n\nUn'analisi di regressione lineare **non consente di inferire direttamente relazioni causali**. L'inferenza causale richiede strumenti e conoscenze specifiche, come:\n- Esperimenti controllati randomizzati, che riducono l'effetto di confondenti non osservati.\n- Modelli di equazioni strutturali o altre tecniche basate su teorie causali, che identificano e separano gli effetti diretti e indiretti.\n\nSolo una volta stabilite le relazioni causali tramite metodi appropriati, i modelli di regressione possono essere utilizzati per quantificare la forza di tali relazioni. Non è possibile procedere nel senso opposto, cioè dedurre nessi causali direttamente dai coefficienti di regressione. Questo errore, noto come **confusione tra correlazione e causalità**, può portare a conclusioni errate e a interpretazioni fuorvianti.\n\nIn conclusione, i coefficienti parziali di regressione sono strumenti utili per descrivere relazioni tra variabili nel contesto di un campione di dati, ma la loro interpretazione causale richiede cautela e metodi appropriati. Per evitare interpretazioni errate:\n\n- Si raccomanda di specificare chiaramente i limiti del modello e delle inferenze derivate.\n- Si consiglia di integrare l'analisi statistica con conoscenze del dominio e tecniche progettate per identificare relazioni causali.\n\nSi vedano le sezioni relative all'**errore di specificazione del modello** e all'**inferenza causale nei modelli di regressione** per ulteriori dettagli su come affrontare questi problemi.\n\n## Quali Predittori Includere nel Modello?\n\nIl modello di regressione multipla può essere utilizzato con due obiettivi principali:\n\n1. **Predizione**: Stimare il valore di $Y$ utilizzando una combinazione lineare delle variabili predittive $X_1, X_2, \\ldots, X_p$. In questo contesto, i coefficienti $\\beta_i$ vengono interpretati come pesi che ottimizzano la previsione di $Y$ sulla base dei valori delle variabili indipendenti.\n\n2. **Descrizione delle relazioni tra variabili**: Analizzare come le variabili indipendenti si associano alla variabile dipendente. Tuttavia, è essenziale ricordare che il modello di regressione multipla **non è progettato per identificare relazioni causali**. Le interpretazioni causali dei coefficienti $\\beta_i$ richiedono cautela e condizioni che spesso non sono soddisfatte nella pratica.\n\nPer stimare correttamente i coefficienti di regressione parziali, il modello deve includere **tutte le variabili rilevanti** che influenzano $Y$. Quando non si includono variabili importanti (omissione di confondenti), o si includono variabili irrilevanti o mal definite, si possono generare errori di specificazione. Questo problema può compromettere sia l'accuratezza delle previsioni sia l'interpretazione delle relazioni tra le variabili.\n\nIn pratica, spesso non conosciamo tutte le variabili rilevanti per il fenomeno in studio. Questo porta a una difficoltà intrinseca nella selezione dei predittori e aumenta il rischio di stime distorte dei coefficienti.\n\n### La \"Insalata Causale\"\n\nTradizionalmente, si riteneva vantaggioso includere nel modello **il maggior numero possibile di variabili** per ottenere un controllo statistico più ampio. Tuttavia, come sottolineato da @McElreath_rethinking, questa strategia può condurre a quello che viene definito \"insalata causale\". Questo termine descrive una situazione in cui:\n\n- Si includono variabili senza una chiara comprensione della loro relazione causale con $Y$ e con le altre variabili predittive.\n- L'inclusione di variabili di controllo inappropriate può causare **distorsioni** nelle stime dei coefficienti, invece di correggerle.\n\nAd esempio, includere una variabile che è influenzata dalla variabile dipendente (feedback causale) può introdurre un bias, peggiorando l'accuratezza del modello.\n\nL'inclusione di variabili di controllo è cruciale in alcuni casi, ma non sempre necessaria. Per evitare distorsioni:\n\n- **Includere variabili confondenti**: Le variabili che influenzano sia la variabile dipendente ($Y$) sia una o più variabili indipendenti ($X_j$) devono essere incluse per ottenere stime non distorte.\n- **Evitare variabili collocate erroneamente nella struttura causale**: Variabili che non influenzano $Y$ o che sono influenzate da $Y$ non dovrebbero essere incluse senza un’adeguata giustificazione teorica o empirica.\n- **Formulare ipotesi causali chiare**: Prima di costruire il modello, è importante definire chiaramente le relazioni causali attese tra le variabili.\n\nL'efficacia e la validità del modello di regressione dipendono strettamente dalla correttezza delle **ipotesi causali** formulate dal ricercatore. La costruzione del modello non dovrebbe limitarsi a essere guidata dai dati osservati, ma dovrebbe riflettere una comprensione teorica del fenomeno in esame. Per superare i limiti dell’“insalata causale”:\n\n- Identificare le variabili chiave che influenzano $Y$ sulla base di una solida comprensione del dominio.\n- Utilizzare strumenti come i diagrammi causali (ad esempio, i DAG - Directed Acyclic Graphs) per mappare le relazioni tra le variabili.\n- Adottare approcci basati su modelli causali, come la regressione stratificata, i modelli di equazioni strutturali o le tecniche di controllo di confondenti (ad esempio, il propensity score matching).\n\nIn conclusione, la scelta delle variabili da includere in un modello di regressione multipla richiede un equilibrio tra controllo statistico e chiarezza causale. Includere troppe variabili senza una giustificazione causale può portare a stime distorte, mentre l’omissione di variabili chiave può compromettere la validità delle conclusioni. La costruzione di modelli validi e utili richiede una combinazione di conoscenza teorica, metodi statistici robusti e attenzione alle ipotesi causali sottostanti.\n\n## Considerazioni Conclusive\n\nIl modello di regressione è uno degli strumenti statistici più utilizzati in psicologia, ma spesso viene applicato con un'interpretazione ingenua e priva di considerazioni critiche. Nel suo libro *Statistical Rethinking*, @McElreath_rethinking introduce una potente metafora per i modelli statistici, paragonandoli ai Golem della mitologia antica: creature di grande forza ma prive di volontà propria, animate solo dall'intento di chi le crea. Sebbene dotati di potere, i Golem possono diventare pericolosi se non guidati con saggezza. Allo stesso modo, i modelli statistici, se usati senza una piena comprensione del contesto e delle loro limitazioni, possono portare a conclusioni errate o fuorvianti.\n\nCome sottolinea @McElreath_rethinking, i modelli statistici sono strumenti costruiti per uno scopo specifico. Essi eseguono calcoli con grande precisione ma non possiedono alcuna comprensione autonoma del contesto in cui vengono applicati. Non rappresentano verità assolute, ma semplificazioni progettate per rispondere a domande specifiche. Questo è particolarmente vero per il modello di regressione, che fornisce risultati numerici concreti ma è limitato nella sua capacità di affrontare questioni complesse, come l’inferenza causale, che richiedono un approccio più articolato e comprensivo.\n\nCome evidenziato da @carlin2023uses, il modello di regressione può essere utilizzato per tre scopi principali:\n\n1. **Descrizione delle associazioni**: Ad esempio, analizzare la prevalenza di una condizione in diverse sottopopolazioni.\n2. **Predizione**: Utilizzare un insieme di predittori per prevedere in modo affidabile il valore di \\(Y\\) per nuovi individui con valori noti di \\(X\\).\n3. **Analisi delle relazioni causali**: Valutare in che misura un intervento o una variabile predittiva influisce su un determinato esito.\n\nUn aspetto cruciale è che i ricercatori chiariscano l'obiettivo per cui applicano il modello di regressione. La mancata distinzione tra questi tre scopi può portare a un uso improprio del modello e a interpretazioni errate. Purtroppo, questa distinzione non è ancora penetrata sufficientemente nell'insegnamento e nella pratica della statistica, soprattutto nei metodi di regressione.\n\nSpesso, nei contesti accademici e applicativi, il modello di regressione viene insegnato e utilizzato come un \"toolkit universale\", con l'obiettivo di trovare il miglior modello per i dati disponibili e successivamente adattare un'interpretazione al modello ottenuto. Tuttavia, @carlin2023uses raccomandano un approccio diverso: insegnare e applicare i modelli di regressione in funzione dello scopo specifico della ricerca. Adottando questa prospettiva:\n\n- Gli aspetti tecnici e teorici del modello vengono introdotti solo quando pertinenti per l'obiettivo della ricerca.\n- Si evita l'applicazione indiscriminata dei modelli, riducendo il rischio di fraintendimenti e interpretazioni improprie.\n\nQuesto approccio non solo promuove un uso più consapevole e mirato dei modelli, ma incoraggia anche una comprensione più profonda delle domande di ricerca e delle limitazioni degli strumenti analitici.\n\nIn conclusione, il modello di regressione è uno strumento prezioso, ma la sua efficacia dipende interamente dalla saggezza e dall'intenzione di chi lo utilizza. Come affermano @McElreath_rethinking e @carlin2023uses, i ricercatori devono applicare i modelli statistici con piena consapevolezza dei loro limiti, chiarendo sempre gli obiettivi della ricerca e utilizzando il modello come strumento per rispondere a domande ben definite. Solo adottando un approccio critico e informato possiamo evitare che questi potenti strumenti si trasformino in Golem incontrollabili, assicurando invece che contribuiscano realmente alla comprensione del mondo che ci circonda.\n\n## Esercizi\n\n::: {#exr-mult-reg-1}\n\nConsidera il seguente modello lineare univariato in forma matriciale:\n\n$$ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} $$\n\nI valori delle variabili indipendenti ($x_1$, $x_2$ e $x_3$) per cinque osservazioni sono:\n\n  $$\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n  $$\n\nI valori della variabile dipendente sono:\n\n$$\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n$$\n\nI coefficienti ($\\beta_0$, $\\beta_1$, $\\beta_2$ e $\\beta_3$) sono:\n\n  $$\n  \\beta_0 = -1.402020, \\quad \\beta_1 = 0.183838, \\quad \\beta_2 = 1.405051, \\quad \\beta_3 = -0.664646\n  $$\n\n1. Determina le matrici $\\mathbf{X}$, $\\boldsymbol{\\beta}$ e $\\boldsymbol{\\epsilon}$ e scrivi l'equazione completa in forma matriciale.\n2. Espandi il modello per ottenere cinque equazioni esplicite, una per ciascuna osservazione, utilizzando i valori forniti.\n3. Trova gli errori casuali ($\\epsilon_1$, $\\epsilon_2$ e $\\epsilon_3$, $\\epsilon_4$, $\\epsilon_5$).\n4. Trova i valori predetti ($\\hat{y}_1$, $\\hat{y}_2$ e $\\hat{y}_3$, $\\hat{y}_4$, $\\hat{y}_5$).\n:::\n\n::: {#exr-mult-reg-2}\n\nObiettivo: calcolare i coefficienti $\\beta$ del modello lineare univariato usando il metodo dei minimi quadrati.\n\nI valori delle variabili indipendenti ($x_1$, $x_2$ e $x_3$) per cinque osservazioni sono:\n\n$$\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n$$\n\nI valori delle variabili dipendenti ($\\mathbf{y}$) sono:\n\n$$\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n$$\n\nLa formula dei minimi quadrati per calcolare i coefficienti $\\beta$ in un modello lineare è data da:\n\n$$ \\boldsymbol{\\beta} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. $$\n\nQuesta formula minimizza la somma dei quadrati degli errori tra i valori osservati e quelli previsti dal modello. In altre parole, cerca di trovare i valori di $\\beta$ che riducono al minimo le discrepanze tra i dati osservati e quelli stimati dal modello lineare.\n\n1. Aggiungi una colonna di 1 alla matrice $\\mathbf{X}$ per includere l'intercetta.\n2. Scrivi la matrice $\\mathbf{X}$ e il vettore $\\mathbf{y}$ utilizzando i dati forniti.\n3. Calcola i coefficienti $\\beta$ utilizzando la formula dei minimi quadrati. Implementa la formula in Python e calcola i valori di $\\beta$. Controlla i risultati usando `pingouin`.\n:::\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] viridis_0.6.5     viridisLite_0.4.2 gridExtra_2.3     patchwork_1.3.0  \n#>  [5] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#>  [9] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [13] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#> [17] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#> [21] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#>  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#>  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-1     \n#> [13] R.oo_1.27.0       rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3   \n#> [17] mgcv_1.9-1        fansi_1.0.6       mnormt_2.1.1      cli_3.6.3        \n#> [21] rlang_1.1.4       R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1    \n#> [25] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#> [29] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#> [33] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.9.0     \n#> [37] gtable_0.3.6      glue_1.8.0        haven_2.5.4       xfun_0.49        \n#> [41] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#> [45] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2\n```\n:::\n\n\n\n\n\n## Bibliografia {.unnumbered}\n\n",
    "supporting": [
      "09_stan_multreg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}