{
  "hash": "e04a4949a5a20436c9293538cf1f2b0d",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Proprietà delle variabili casuali {#sec-prob-random-var-properties}\n\n**Prerequisiti**\n\nPrima di affrontare il presente capitolo, è essenziale leggere la sezione @sec-calculus.\n\n**Concetti e Competenze Chiave**\n\n- Approfondire i concetti di valore atteso e varianza per variabili casuali discrete.\n- Acquisire familiarità con le principali proprietà associate al valore atteso e alla varianza.\n- Estendere la comprensione di valore atteso e varianza alle variabili casuali continue.\n- Utilizzare R per calcolare effettivamente queste metriche.\n- Interpretare criticamente i risultati ottenuti dalle analisi.\n\n**Preparazione del Notebook**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)\n```\n:::\n\n\n\n\n## Introduzione \n\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici è spesso molto utile. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il \"baricentro\") e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale. \n\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.\n\n## Valore Atteso\n\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo \"valore tipico\". Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n- **Media**: La somma dei valori divisa per il numero dei valori.\n- **Mediana**: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n- **Moda**: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori $\\{3, 1, 4, 1, 5\\}$, la media è $\\frac{3+1+4+1+5}{5} = 2.8$, la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per \"valore tipico\" in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\n::: {#def-}\n\nSia $X$ una variabile casuale discreta che assume i valori $x_1, \\dots, x_n$ con probabilità $P(X = x_i) = p(x_i)$. Il *valore atteso* di $X$, denotato con $\\mathbb{E}(X)$, è definito come:\n\n$$\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n$$\n\n:::\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\n::: {#exm-}\nCalcoliamo il valore atteso della variabile casuale $X$ corrispondente al lancio di una moneta equilibrata, dove *testa* corrisponde a $X = 1$ e *croce* corrisponde a $X = 0$:\n\n$$\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n$$\n:::\n\n::: {#exm-}\nCalcoliamo il valore atteso della variabile casuale $X$ che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\n\nCome abbiamo visto nel @sec-prob-intro-random-var, $X$ può assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con una distribuzione di massa di probabilità pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando la formula del valore atteso, otteniamo:\n\n$$\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n$$\n\n:::\n\n::: {#exm-}\n\nVediamo ora come eseguire i calcoli del valore atteso utilizzando R. Per prima cosa, definiamo i valori della variabile casuale:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 2:12\nx\n#>  [1]  2  3  4  5  6  7  8  9 10 11 12\n```\n:::\n\n\n\n\nSuccessivamente, calcoliamo la distribuzione di massa della variabile casuale.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire il range dei valori dei dadi\nr <- 1:6\nsample <- expand.grid(i = r, j = r)  # Tutte le combinazioni dei valori dei due dadi\n\n# Calcolare la distribuzione di probabilità\npx <- numeric()\n\nfor (sum_value in 2:12) {\n  event <- subset(sample, i + j == sum_value)  # Filtra le combinazioni che sommano a 'sum_value'\n  px <- c(px, nrow(event) / nrow(sample))  # Calcola la probabilità\n}\n\npx\n#>  [1] 0.0278 0.0556 0.0833 0.1111 0.1389 0.1667 0.1389 0.1111 0.0833 0.0556\n#> [11] 0.0278\n```\n:::\n\n\n\n\nOra, possiamo calcolare il valore atteso di $X$ utilizzando la formula del valore atteso per variabili casuali discrete:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nex <- sum(x * px)\nround(ex, 3)\n#> [1] 7\n```\n:::\n\n\n\n\nIn alternativa, possiamo utilizzare un approccio più diretto utilizzando le funzioni per la definizione di distribuzioni discrete in R. In questo caso, definiamo manualmente la distribuzione:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 2:12\npx <- c(1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36)\n\n# Calcoliamo il valore atteso direttamente:\nx_ev <- sum(x * px)\nround(x_ev, 3)\n#> [1] 7\n```\n:::\n\n\n\n\nQuesti metodi dimostrano come sia possibile calcolare il valore atteso di una variabile casuale sia attraverso un approccio diretto, sia utilizzando R.\n\n:::\n\n### Interpretazione\n\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\n\nPer chiarire questo concetto, consideriamo nuovamente l'esempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale $X$ rappresenta la \"somma dei due dadi\". Per interpretare il valore atteso, possiamo simulare un grande numero di realizzazioni indipendenti di $X$ utilizzando la funzione `np.random.choice()` della libreria NumPy. Questa funzione permette di generare campioni casuali basati sui valori della variabile casuale, sul numero di ripetizioni indipendenti (qui 1.000.000) e sulla distribuzione di massa di probabilità associata:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)  # Per rendere i risultati riproducibili\nx_samples <- sample(x, size = 1e6, replace = TRUE, prob = px)\n```\n:::\n\n\n\n\nL'istruzione `sample(x, size = 1e6, replace = TRUE, prob = px))` utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro `size`), selezionati casualmente dall'array `x` secondo le probabilità specificate nell'array `px`.\n\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(x_samples) |>\n  round(3)\n#> [1] 7\n```\n:::\n\n\n\n\nQuesto risultato conferma che, con un numero elevato di simulazioni, la media aritmetica dei valori ottenuti fornisce una buona approssimazione del valore atteso teorico di $X$.\n\n### Proprietà del Valore Atteso\n\nUna delle proprietà più importanti del valore atteso è la sua **linearità**: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\n$$\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n$$ {#eq-prop-expval-linearity}\n\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando $X$ e $Y$ sono variabili casuali indipendenti, ma è valida anche nel caso in cui $X$ e $Y$ siano correlate.\n\nInoltre, se moltiplichiamo una variabile casuale per una costante $c$, il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\n$$\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n$$  {#eq-prop-expval-const}\n\nQuesta proprietà ci dice che una costante può essere \"estratta\" dall'operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\n\nUn'altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se $X$ e $Y$ sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\n$$\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n$$ {#eq-expval-prod-ind-rv}\n\nInfine, consideriamo la media aritmetica $\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}$ di $n$ variabili casuali indipendenti con la stessa distribuzione e con valore atteso $\\mu$. Il valore atteso della media aritmetica è:\n\n$$\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n$$\n\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l'analisi statistica e probabilistica.\n\n::: {#exm-}\n\nConsideriamo il seguente esperimento casuale. Sia $Y$ il numero che si ottiene dal lancio di un dado equilibrato a sei facce e $Y$ il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di $X+Y$.\n\nPer risolvere il problema iniziamo a costruire lo spazio campione dell'esperimento casuale.\n\n| $x /\\ y$ |   1    |   2    |   3    |   4    |   5    |   6    |\n|:--------------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|          0           | (0, 1) | (0, 2) | (0, 3) | (0, 4) | (0, 5) | (0, 6) |\n|          1           | (1, 1) | (1, 2) | (1, 3) | (1, 4) | (1, 5) | (1, 6) |\n\novvero\n\n| $x /\\ y$ |  1  |  2  |  3  |  4  |  5  |  6  |\n|:--------------------:|:---:|:---:|:---:|:---:|:---:|:---:|\n|          0           |  1  |  2  |  3  |  4  |  5  |  6  |\n|          1           |  2  |  3  |  4  |  5  |  6  |  7  |\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero $P(\\omega) = \\frac{1}{12}$. Il valore atteso di $X+Y$ è dunque uguale a:\n\n$$\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n$$\n\nSi ottiene lo stesso risultato usando l'@eq-prop-expval-linearity:\n\n$$\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n$$\n\n:::\n\n::: {#exm-}\n\nSvolgiamo ora l'esercizio in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoin <- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie <- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample <- expand.grid(coin = coin, die = die)\nprint(sample)\n#>    coin die\n#> 1     0   1\n#> 2     1   1\n#> 3     0   2\n#> 4     1   2\n#> 5     0   3\n#> 6     1   3\n#> 7     0   4\n#> 8     1   4\n#> 9     0   5\n#> 10    1   5\n#> 11    0   6\n#> 12    1   6\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npx <- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event <- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob <- nrow(event) / nrow(sample)\n  px <- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#> P(X + Y = 1) = 1 / 12\n#> P(X + Y = 2) = 2 / 12\n#> P(X + Y = 3) = 2 / 12\n#> P(X + Y = 4) = 2 / 12\n#> P(X + Y = 5) = 2 / 12\n#> P(X + Y = 6) = 2 / 12\n#> P(X + Y = 7) = 1 / 12\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value <- sum(x * px)\nexpected_value\n#> [1] 4\n```\n:::\n\n\n\n\n:::\n\n::: {#exm-}\nConsideriamo le variabili casuali $X$ e $Y$ definite nel caso del lancio di tre monete equilibrate, dove $X$ conta il numero delle teste nei tre lanci e $Y$ conta il numero delle teste al primo lancio. Si calcoli il valore atteso di $Z = X \\cdot Y$.\n\nLa distribuzione di probabilità congiunta $P(X, Y)$ è fornita nella tabella seguente.\n\n| $x /\\ y$ |  0  |  1  | $p(Y)$ |\n|:--------------------:|:---:|:---:|:------:|\n|          0           | 1/8 |  0  |  1/8   |\n|          1           | 2/8 | 1/8 |  3/8   |\n|          2           | 1/8 | 2/8 |  3/8   |\n|          3           |  0  | 1/8 |  1/8   |\n|        $p(y)$        | 4/8 | 4/8 |  1.0   |\n\nIl calcolo del valore atteso di $XY$ si riduce a\n\n$$\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n$$\n\nSi noti che le variabili casuali $Y$ e $Y$ non sono indipendenti. Dunque non possiamo usare l'@eq-expval-prod-ind-rv. Infatti, il valore atteso di $X$ è\n\n$$\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n$$\n\ne il valore atteso di $Y$ è\n\n$$\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n$$\n\nPerciò\n\n$$\n1.5 \\cdot 0.5 \\neq 1.0.\n$$\n\n:::\n\n### Variabili casuali continue\n\nNel caso di una variabile casuale continua $X$, il valore atteso è definito come:\n\n$$\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n$$\n\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di $x$, dove ogni possibile valore di $x$ è ponderato in base alla densità di probabilità $p(x)$. \n\nL'integrale può essere interpretato analogamente a una somma continua, in cui $x$ rappresenta la posizione delle barre infinitamente strette di un istogramma, e $p(x)$ rappresenta l'altezza di tali barre. La notazione $\\int_{-\\infty}^{+\\infty}$ indica che si sta sommando il contributo di ogni valore possibile di $x$ lungo l'intero asse reale.\n\nQuesta interpretazione rende chiaro come l'integrale calcoli una somma ponderata che si estende su tutti i possibili valori di $x$, fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell'integrale, si veda l'@sec-calculus.\n\n#### Moda\n\nUn'altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di $Y$ individua il valore $y$ più plausibile, ovvero il valore $y$ che massimizza la funzione di densità $p(y)$:\n\n$$\nMo(Y) = \\text{argmax}_y p(y).\n$$ {#eq-def-mode}\n\n::: {.callout-note}\nLa notazione $\\text{argmax}_y p(y)$ significa: il valore $y$ tale per cui la funzione $p(y)$ assume il suo valore massimo.\n:::\n\n## Varianza\n\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la *varianza*.\n\n::: {#def-}\nSe $X$ è una variabile casuale discreta con distribuzione $p(x)$, la varianza di $X$, denotata con $\\mathbb{V}(X)$, è definita come:\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n$$ {#eq-def-var-rv}\n:::\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di $X$ con $\\mu = \\mathbb{E}(X)$, la varianza $\\mathbb{V}(X)$ diventa il valore atteso di $(X - \\mu)^2$.\n\n### Interpretazione della Varianza\n\nLa varianza rappresenta una misura della \"dispersione\" dei valori di $X$ intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di $X$ tendono a differire dalla media $\\mu$. \n\nPer capire meglio, consideriamo la variabile casuale $X - \\mathbb{E}(X)$, detta *scarto* o *deviazione* dalla media. Questa variabile rappresenta le \"distanze\" tra i valori di $X$ e il valore atteso $\\mathbb{E}(X)$. Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione. \n\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo $(X - \\mathbb{E}(X))^2$, che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di $X$ rispetto alla sua media. \n\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\n::: {#exm-}\n\nPosta $S$ uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di $S$.\n\nLa variabile casuale $S$ ha la seguente distribuzione di probabilità:\n\n|    $s$     |       2        |       3        |       4        |       5        |       6        |       7        |       8        |       9        |       10       |       11       |       12       |\n|:----------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|\n| $P(S = s)$ | $\\frac{1}{36}$ | $\\frac{2}{36}$ | $\\frac{3}{36}$ | $\\frac{4}{36}$ | $\\frac{5}{36}$ | $\\frac{6}{36}$ | $\\frac{5}{36}$ | $\\frac{4}{36}$ | $\\frac{3}{36}$ | $\\frac{2}{36}$ | $\\frac{1}{36}$ |\n\nEssendo $\\mathbb{E}(S) = 7$, la varianza diventa\n\n$$\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n$$\n\n:::\n\n::: {#exm-}\n\nSvolgiamo l'esercizio in R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire i valori di x e le loro probabilità px\nx <- 2:12\npx <- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex <- sum(x * px)\nex\n#> [1] 7\n```\n:::\n\n\n\n\nApplichiamo l'@eq-def-var-rv:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolo della varianza utilizzando la definizione\nvariance <- sum((x - ex)^2 * px)\nvariance\n#> [1] 5.83\n```\n:::\n\n\n\n\nUsiamo la funzione `var()` di `rv_discrete`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolo della varianza con pesi\nvariance_check <- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#> [1] 5.83\n```\n:::\n\n\n\n\n:::\n\n### Formula Alternativa per la Varianza\n\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale $X$:\n\n$$\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n$$\n\ndove $\\mathbb{E}(X)$ è una costante. Semplificando ulteriormente, otteniamo:\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n$$ {#eq-def-alt-var-rv}\n\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di $X$ e il quadrato della media di $X$.\n\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di $X$. Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\n::: {#exm-}\n\nConsideriamo la variabile casuale $X$ che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di $Y$.\n\nIl valore atteso di $X$ è\n\n$$\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n$$\n\nUsando la formula tradizionale della varianza otteniamo:\n\n$$\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n$$\n\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di $X^2$ è\n\n$$\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n$$\n\ne la varianza diventa\n\n$$\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n$$\n\n:::\n\n::: {#exm-}\n\nSvolgiamo l'esercizio in R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire i valori di x e le probabilità px\nx <- c(0, 1)\npx <- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult <- sum(x^2 * px) - (sum(x * px))^2\nresult\n#> [1] 0.16\n```\n:::\n\n\n\n\n:::\n\n### Proprietà\n\n**Segno della varianza.** La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume  un solo valore.\n\n**Invarianza per traslazione.** La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n  \n$$\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n$$\n\n*Dimostrazione.* Iniziamo a scrivere\n\n$$\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n$$\n\nQuindi\n\n$$\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n$$\n\nEsaminiamo una dimostrazione numerica.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire i valori di x\nx <- c(2, 1, 4, 7)\n\n# Calcolare y\ny <- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult <- var(y) == 2^2 * var(x)\nresult\n#> [1] TRUE\n```\n:::\n\n\n\n\n**Varianza della somma di due variabili indipendenti.** La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\n$$\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n*Dimostrazione.* Se $\\mathbb{E}(X) = \\mathbb{E}(Y) = 0$, allora $\\mathbb{E}(X+Y) = 0$ e \n\n$$\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).$$ \n\nSiccome le variabili sono indipendenti risulta $\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0$. \n\n**Varianza della differenza di due variabili indipendenti.** La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\n$$\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n*Dimostrazione.*\n\n$$\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n$$\n\n**Varianza della somma di due variabili non indipendenti.** Se $X$ e $Y$ non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\n$$\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n$$\n\ndove $Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)$.\n\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire i valori di x e y\nx <- c(2, 1, 4, 7)\ny <- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y <- mean((x + y - mean(x + y))^2)\nvar_x_y\n#> [1] 35.2\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire i valori di x e y\nx <- c(2, 1, 4, 7)\ny <- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult <- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#> [1] 35.2\n```\n:::\n\n\n\n\n**Varianza della media di variabili indipendenti.** La media aritmetica \n$\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}$ di $n$ variabili casuali indipendenti aventi la medesima distribuzione, ha varianza \n\n$$\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n$$\n\nIl principio precedente è illustrato dalla seguente simulazione.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation <- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size <- 30\nnum_samples <- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means <- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample <- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] <- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var <- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#> [1] 3.33\n```\n:::\n\n\n\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n10^2 / 30\n#> [1] 3.33\n```\n:::\n\n\n\n\n### Variabili casuali continue\n\nPer una variabile casuale continua $X$, la varianza è definita come:\n\n$$\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n$$ {#eq-def-var-rv-cont}\n\nAnalogamente al caso discreto, la varianza di una variabile casuale continua $X$ una misura della dispersione, ovvero la \"distanza\" media quadratica attesa dei valori $x$ rispetto alla loro media \n$\\mathbb{E}(X)$. In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.\n\n## Deviazione Standard\n\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all'unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato *deviazione standard* ed è comunemente indicato con la lettera greca $\\sigma$.\n\n::: {#def-}\nLa deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\n$$\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n$$\n:::\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la \"distanza\" tipica o prevista dei valori $x$ rispetto alla loro media.\n\n::: {#exm-}\n\nPer i dadi equilibrati dell'esempio precedente, la deviazione standard della variabile casuale $S$ è pari a $\\sqrt{5.833} = 2.415$. Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.\n\n:::\n\n## Standardizzazione\n\n::: {#def-}\nData una variabile casuale $X$, si dice *variabile standardizzata* di $X$ l'espressione\n\n$$\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n$$ {#eq-standardization}\n:::\n\nSolitamente, una variabile standardizzata viene denotata con la lettera $Z$.\n\n## Il Teorema di Chebyshev\n\nIl *Teorema di Chebyshev* ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori \"estremi\".\n\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k > 0, si ha:\n\n$$\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n$$\n\ndove:\n\n* P(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\n* σ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n* **Limite superiore:** Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n* **Qualsiasi distribuzione:** La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n* **Utilizzo:** Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\n::: {#exm-chebyshev}\n\nSupponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell'intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\n\n```\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\n```\n\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell'intervallo [90, 110].\n\n:::\n\n## Momenti di variabili casuali\n\n::: {#def-}\nSi chiama *momento* di ordine $q$ di una v.c. $X$, dotata di densità $p(x)$, la quantità\n\n$$\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n$$ {#eq-moments-cont}\n\nSe $X$ è una v.c. discreta, i suoi momenti valgono:\n\n$$\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n$$ {#eq-moments-discr}\n\ndove:\n\n- $E(X^q)$ rappresenta il valore atteso di $X$ elevato alla $q$-esima potenza.\n- $x_i$ sono i possibili valori della variabile discreta.\n- $P(x_i)$ è la probabilità associata a ciascun valore discreto.\n:::\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\n1. Il momento del primo ordine ($q$ = 1): corrisponde al valore atteso (o media) della variabile casuale $X$.\n2. Il momento del secondo ordine ($q$ = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di $X$. Questo si ottiene applicando una traslazione: $x_0 = x − \\mathbb{E}(X)$, dove $x_0$ rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.\n\n\n## Alcuni esempi in R\n\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\n\nConsideriamo una variabile casuale $X$ che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\n\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 0:6\nprint(x)\n#> [1] 0 1 2 3 4 5 6\n```\n:::\n\n\n\n\nIl vettore `px` conterrà le probabilità associate ai valori `x`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npx <- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#> [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n```\n:::\n\n\n\n\nControlliamo che la somma sia 1:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(px)\n#> [1] 1\n```\n:::\n\n\n\n\nCalcoliamo il valore atteso di $X$ implementando la formula del valore atteso utilizzando i vettori `x` e `px`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_ev <- sum(x * px)\nx_ev\n#> [1] 2.7\n```\n:::\n\n\n\n\nCalcoliamo la varianza di $X$ usando i vettori `x` e `px`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_var <- sum((x - x_ev)^2 * px)\nx_var\n#> [1] 3.81\n```\n:::\n\n\n\n\nCalcoliamo la deviazione standard di $X$ prendendo la radice quadrata della varianza:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_sd <- sqrt(x_var)\nx_sd\n#> [1] 1.95\n```\n:::\n\n\n\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare `ggplot2`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n```\n\n::: {.cell-output-display}\n![](06_expval_var_files/figure-html/unnamed-chunk-26-1.png){width=576}\n:::\n:::\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.\n\n## Riflessioni Conclusive\n\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il \"valore tipico\" che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l'analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] mice_3.17.0       viridis_0.6.5     viridisLite_0.4.2 gridExtra_2.3    \n#>  [5] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#>  [9] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#> [13] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#> [17] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#> [21] rio_1.2.3         here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#>  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#>  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pan_1.9          \n#> [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1     \n#> [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#> [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10      \n#> [25] glmnet_4.1-8      nloptr_2.1.1      pillar_1.9.0      MASS_7.3-61      \n#> [29] iterators_1.0.14  rpart_4.1.23      boot_1.3-31       mitml_0.4-5      \n#> [33] foreach_1.5.2     nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37    \n#> [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#> [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.3        \n#> [45] magrittr_2.0.3    survival_3.7-0    utf8_1.2.4        broom_1.0.7      \n#> [49] withr_3.0.2       backports_1.5.0   timechange_0.3.0  rmarkdown_2.29   \n#> [53] nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3         evaluate_1.0.1   \n#> [57] rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0        minqa_1.2.8      \n#> [61] jsonlite_1.8.9    R6_2.5.1\n```\n:::\n",
    "supporting": [
      "06_expval_var_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}