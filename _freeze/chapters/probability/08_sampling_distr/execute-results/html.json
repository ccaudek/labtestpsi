{
  "hash": "c2fc2d7622f3cfd800ca103acf5dd3f2",
  "result": {
    "engine": "knitr",
    "markdown": "# Stime, stimatori e parametri {#sec-prob-sampling-distr}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- comprendere e analizzare come le stime dei parametri della popolazione variano da campione a campione;\n- definire le nozioni di popolazione, campione, parametro, stima e stimatore;\n- esplorare la connessione tra stime campionarie e parametri reali della popolazione;\n- calcolare e interpretare il valore atteso e la varianza della media campionaria;\n- utilizzare l'errore standard per rappresentare l'incertezza nelle stime dei parametri;\n- comprendere la convergenza delle medie campionarie alla media della popolazione;\n- applicare il teorema per approssimare distribuzioni campionarie con distribuzioni normali;\n- analizzare la distribuzione campionaria di statistiche come la varianza e il valore massimo del campione.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere \n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n\n\n:::\n\n## Introduzione \n\nIn questo capitolo, approfondiremo il concetto di *distribuzione campionaria* che costituisce uno dei pilastri dell'inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell'inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.\n\n## Popolazione e campioni\n\nNell'analisi dei dati, l'obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata *parametro*. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata *stima*, e la formula che utilizziamo per ottenerla è conosciuta come *stimatore*. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un'approssimazione del parametro di interesse.\n\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l'indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n\nÈ importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento. \n\n## La relazione tra stime e parametri\n\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con $\\mu$. Il nostro obiettivo è capire e caratterizzare l'incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l'approccio frequentista, facendo uso di un importante strumento statistico chiamato *distribuzione campionaria*.\n\n### Distribuzione campionaria\n\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\n\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\n\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all'intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di $\\mu$. Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell'incertezza legata al processo di stima.\n\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(2, 4.5, 5, 5.5)\nx\n#> [1] 2.0 4.5 5.0 5.5\n```\n:::\n\n\n\n\nL'istogramma seguente descrive la distribuzione di frequenza della popolazione.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n  )\n#> Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `after_stat(density)` instead.\n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-3-1.png){width=576}\n:::\n:::\n\n\n\n\nStampiamo gli intervalli utilizzati per l'istogramma.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolo degli intervalli e delle frequenze per l'istogramma\nhist_data <- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa degli intervalli e delle frequenze relative\ncat(\"Intervalli utilizzati per l'istogramma:\", hist_data$breaks, \"\\n\")\n#> Intervalli utilizzati per l'istogramma: 2 2.5 3 3.5 4 4.5 5 5.5\ncat(\"Frequenze relative utilizzate per l'istogramma:\", hist_data$density, \"\\n\")\n#> Frequenze relative utilizzate per l'istogramma: 0.5 0 0 0 0.5 0.5 0.5\n\n# Calcolo delle frequenze assolute\nhist_data_abs <- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa delle frequenze assolute\ncat(\"Frequenze assolute utilizzate per l'istogramma:\", hist_data_abs$counts, \"\\n\")\n#> Frequenze assolute utilizzate per l'istogramma: 1 0 0 0 1 1 1\n```\n:::\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolo della media e della varianza della popolazione\nmean_x <- mean(x)\nvar_x <- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nc(mean_x, var_x)\n#> [1] 4.25 1.81\n```\n:::\n\n\n\n\nSupponiamo ora di voler considerare l'estrazione di tutti i possibili campioni di dimensione $n = 2$ da una popolazione rappresentata dal vettore `x`. Per fare ciò, possiamo fare uso della funzione `expand.grid` in R, che permette di generare tutte le combinazioni possibili di valori con ripetizione.\n\nUtilizzando `expand.grid`, otteniamo un `data.frame` in cui ogni riga rappresenta una coppia di valori possibili. La struttura risultante contiene tutte le combinazioni in cui ogni valore nel vettore `x` può essere abbinato a se stesso o a un altro valore nel vettore. Convertendo il risultato in una matrice, otteniamo una rappresentazione simile a un array NumPy, con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie formate dai valori del vettore `x`.\n\nQuesto approccio è coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento può essere scelto più di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sarà $4^2 = 16$. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di $4 \\times 4 = 16$ possibili coppie.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creare tutte le combinazioni possibili di valori\nsamples <- expand.grid(x, x)\nsamples <- as.matrix(samples)  # Convertire in matrice\nprint(samples)\n#>       Var1 Var2\n#>  [1,]  2.0  2.0\n#>  [2,]  4.5  2.0\n#>  [3,]  5.0  2.0\n#>  [4,]  5.5  2.0\n#>  [5,]  2.0  4.5\n#>  [6,]  4.5  4.5\n#>  [7,]  5.0  4.5\n#>  [8,]  5.5  4.5\n#>  [9,]  2.0  5.0\n#> [10,]  4.5  5.0\n#> [11,]  5.0  5.0\n#> [12,]  5.5  5.0\n#> [13,]  2.0  5.5\n#> [14,]  4.5  5.5\n#> [15,]  5.0  5.5\n#> [16,]  5.5  5.5\n```\n:::\n\n\n\n\nLa matrice `samples` è bidimensionale, dove ogni riga rappresenta una coppia di valori. Per calcolare la media di ogni campione di ampiezza $n = 2$, possiamo utilizzare la funzione `rowMeans`, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la *distribuzione campionaria* delle medie dei campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolare la media di ciascun campione\nmeans <- rowMeans(samples)\nprint(means)\n#>  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#> [15] 5.25 5.50\n```\n:::\n\n\n\n\nLa funzione `rowMeans(samples)` calcola la media per ogni riga della matrice `samples`. Una rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x` è fornita qui sotto.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Istogramma delle medie campionarie\nggplot(data.frame(means), aes(x = means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n)\n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-8-1.png){width=576}\n:::\n:::\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creare un data frame con i campioni e le loro medie\ndf <- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#>     Samples x_bar\n#> 1      2, 2  2.00\n#> 2    4.5, 2  3.25\n#> 3      5, 2  3.50\n#> 4    5.5, 2  3.75\n#> 5    2, 4.5  3.25\n#> 6  4.5, 4.5  4.50\n#> 7    5, 4.5  4.75\n#> 8  5.5, 4.5  5.00\n#> 9      2, 5  3.50\n#> 10   4.5, 5  4.75\n#> 11     5, 5  5.00\n#> 12   5.5, 5  5.25\n#> 13   2, 5.5  3.75\n#> 14 4.5, 5.5  5.00\n#> 15   5, 5.5  5.25\n#> 16 5.5, 5.5  5.50\n```\n:::\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza $n = 2$ che possono essere estratti dalla popolazione `x`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolare la media delle medie campionarie\nmean_of_means <- mean(means)\nprint(mean_of_means)\n#> [1] 4.25\n```\n:::\n\n\n\n\n### Valore atteso della media campionaria\n\nSupponiamo che $ X_1, X_2, \\ldots, X_n $ siano variabili aleatorie iid con valore atteso $ \\mu $ e varianza $ \\sigma^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\n$$\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \n$$\n\nEcco la dimostrazione:\n\n$$\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n$$\n\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid è uguale al valore atteso di ciascuna variabile singola, che in questo caso è $ \\mu $.\n\nVerifichiamo che ciò sia vero nel nostro caso specifico.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(x)\n#> [1] 4.25\nmean(means)\n#> [1] 4.25\n```\n:::\n\n\n\n\n### Varianza della media campionaria\n\nDato che le variabili $X_1, X_2, \\ldots, X_n$ sono indipendenti ed identicamente distribuite (iid) con valore atteso $\\mu$ e varianza $\\sigma^2$, possiamo calcolare la varianza della media campionaria $\\bar{X}$ come segue:\n\n$$\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n$$\n\nQuindi, la varianza della media campionaria di $n$ variabili iid è uguale alla varianza di ciascuna variabile singola divisa per $n$, che in questo caso è $\\sigma^2/n$.\n\nPer l'esempio in discussione, il valore della varianza delle medie dei campioni è dunque pari a\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(x) * ((length(x) - 1)/ length(x)) / 2\n#> [1] 0.906\n```\n:::\n\n\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(means) * ((length(means) - 1)/ length(means))\n#> [1] 0.906\n```\n:::\n\n\n\n\nConsideriamo ora un particolare campione. Per esempio\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_sample = c(5, 5.5)\nprint(observed_sample)\n#> [1] 5.0 5.5\n```\n:::\n\n\n\n\nTroviamo la media del campione:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_mean = mean(observed_sample)\nprint(sample_mean)\n#> [1] 5.25\n```\n:::\n\n\n\n\nLa media del campione è diversa dalla media della popolazione ($\\mu$ = 4.25).\n\nTroviamo la deviazione standard del campione:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_sd = sqrt(var(observed_sample)/2)\nprint(sample_sd)\n#> [1] 0.25\n```\n:::\n\n\n\n\nLa deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqrt(var(x) * (length(x) - 1)/length(x))\n#> [1] 1.35\n```\n:::\n\n\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall'analisi delle medie campionarie:\n\n1. **Media delle medie campionarie e media della popolazione**: La media della distribuzione delle medie campionarie è identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ \\mu $ è:\n\n$$\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n$$\n\n2. **Varianza delle medie campionarie e varianza della popolazione**: La varianza della distribuzione delle medie campionarie è inferiore alla varianza della popolazione e, precisamente, è pari alla varianza della popolazione divisa per la dimensione del campione:\n\n$$\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n$$\n\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\n\nInoltre, è importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\n- Se la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sarà anch'essa normale.\n- Se la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.\n\n## Errore standard e rappresentazione dell'incertezza inferenziale\n\nNella statistica inferenziale, l'errore standard è una misura frequentemente utilizzata per rappresentare l'incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L'errore standard quantifica quanto possa variare la stima di una statistica da un campione all'altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di \"media più o meno uno (o due) errori standard.\" Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.\n\nL'uso dell'errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l'incertezza inferenziale. Contribuisce alla comprensione dell'affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell'errore standard può essere problematico [@ward2022control].\n\n## Legge dei Grandi Numeri\n\nLa Legge dei Grandi Numeri (LLN) è un principio fondamentale della teoria delle probabilità che stabilisce come, incrementando il numero $n$ di osservazioni, la media campionaria $\\bar{X}_n$ tenda asintoticamente alla media teorica $\\mu$. La LLN si articola in due varianti: la versione \"forte\" e quella \"debole\", le quali differiscono per il tipo di convergenza verso la media attesa.\n\n### Versione Forte della Legge dei Grandi Numeri (SLLN)\n\nLa SLLN afferma che la media campionaria $ \\bar{X}_n $ converge quasi certamente alla media teorica $\\mu$, ovvero la convergenza avviene con probabilità 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell'insieme campionario $S$, $\\bar{X}_n(s)$ tende a $\\mu$, ad eccezione di un insieme di eventi $B_0$ la cui probabilità è zero. In termini tecnici, si dice che $\\bar{X}_n$ converge a $\\mu$ \"quasi certamente\".\n\n### Versione Debole della Legge dei Grandi Numeri (WLLN)\n\nLa WLLN afferma che, per ogni $\\epsilon > 0$, la probabilità che la media campionaria $\\bar{X}_n$ si discosti da $\\mu$ di una quantità maggiore di $\\epsilon$ tende a zero all'aumentare di $n$. Questo fenomeno è definito come convergenza in probabilità verso la media teorica $\\mu$.\n\n### Implicazioni e Applicazioni\n\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, più in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l'utilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l'affidabilità delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\n::: {#exm-}\n\nSiano $X_1, X_2, \\ldots$ variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro $1/2$. Interpretando gli $X_j$ come indicatori di \"Testa\" in una sequenza di lanci di una moneta equa, $\\bar{X}_n$ rappresenta la proporzione di \"Testa\" dopo $n$ lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie $\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots$ convergerà a $1/2$ quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di \"Testa\" (HHHHHH...) o sequenze irregolari come HHTHHTHHTHHT..., ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni $\\epsilon > 0$, la probabilità che $\\bar{X}_n$ sia distante più di $\\epsilon$ da $1/2$ può essere resa arbitrariamente piccola aumentando $n$.\n\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato $\\bar{X}_n$ in funzione di $n$. Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra $\\bar{X}_n$ in funzione di $ n $ per ciascuna delle sei sequenze. All'inizio, notiamo una certa variazione nella proporzione cumulativa di \"Testa\". Tuttavia, con l'aumentare del numero di lanci, la varianza $ \\text{Var}(\\bar{X}_n) $ diminuisce progressivamente e $\\bar{X}_n$ tende a $1/2$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Numero di sequenze\nnum_sequences <- 6\n# Numero di lanci\nnum_tosses <- 300\n\n# Creare un data frame per contenere i risultati\nresults <- data.frame(Toss = numeric(), Proportion = numeric(), Sequence = character())\n\n# Loop attraverso ciascuna sequenza\nfor (i in 1:num_sequences) {\n  # Generare una sequenza di lanci di moneta equa (Testa=1, Croce=0)\n  coin_tosses <- sample(c(0, 1), num_tosses, replace = TRUE)\n  \n  # Calcolare la proporzione cumulativa di Teste\n  running_proportion <- cumsum(coin_tosses) / seq_along(coin_tosses)\n  \n  # Aggiungere i risultati al data frame\n  results <- rbind(\n    results,\n    data.frame(\n      Toss = seq_along(coin_tosses),\n      Proportion = running_proportion,\n      Sequence = paste(\"Sequence\", i)\n    )\n  )\n}\n\n# Creare il grafico con ggplot2\nggplot(results, aes(x = Toss, y = Proportion, color = Sequence)) +\n  geom_line() +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Number of Tosses\",\n    y = \"Running Proportion of Heads\",\n    title = \"Running Proportion of Heads in Six Sequences of Fair Coin Tosses\",\n    color = \"Sequence\"\n  ) \n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-18-1.png){width=576}\n:::\n:::\n\n\n\n\n:::\n\n## Teorema del Limite Centrale\n\nIl teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale.\n\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), $Y = Y_1, \\dots, Y_i, \\ldots, Y_n$, ciascuna con valore atteso $\\mathbb{E}(Y_i) = \\mu$ e deviazione standard $SD(Y_i) = \\sigma$. Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\n$$\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n$$\n\nAllora, quando $n$ tende all'infinito, la distribuzione di $Z$ convergerà a una distribuzione normale con media $\\mu$ e deviazione standard ridotta di un fattore $\\frac{1}{\\sqrt{n}}$:\n\n$$\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n$$\n\n### Significato e generalizzazione\n\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\n\nAd esempio, l'altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\n::: {#exm-}\n\nPer visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione distribuita in maniera uniforme. Estraiamo 300 campioni di dimensione $n$ = 30 da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un'illustrazione concreta dell'efficacia del TLC nell'approssimare distribuzioni reali.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the random seed for reproducibility\nset.seed(42)\n\n# Generate a non-normally distributed population\npopulation <- runif(5000, min = 0, max = 1)\n\n# Create a histogram of the population\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for plotting\n\n# Plot the histogram of the population\nhist(population, breaks = 30, prob = TRUE, main = \"Population Distribution\",\n     xlab = \"Value\", col = \"lightblue\")\n\n# Step 2 and 3: Draw random samples and calculate sample means\nsample_size <- 30\nnum_samples <- 300\n\n# Empty vector to store sample means\nsample_means <- c()\n\nfor (i in 1:num_samples) {\n  # Take a random sample\n  sample <- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calculate the mean of the sample\n  sample_means[i] <- mean(sample)\n}\n\n# For sample\nx_bar <- mean(sample_means)\nstd <- sd(sample_means)\n\nprint('Sample Mean and Variance')\n#> [1] \"Sample Mean and Variance\"\nprint(x_bar)\n#> [1] 0.501\nprint(std**2)\n#> [1] 0.00275\n\n# For Population\nmu <- mean(population)\nsigma <- sd(population)\n\nprint('Population Mean and Variance')\n#> [1] \"Population Mean and Variance\"\nprint(mu)\n#> [1] 0.503\nprint((sigma**2)/sample_size)\n#> [1] 0.00282\n\n# Plot the histogram of sample means\nhist(sample_means, breaks = 30, prob = TRUE, main = \"Distribution of Sample Means\",\n     xlab = \"Sample Mean\", col = \"lightgreen\")\n\n# Overlay density curves\ncurve(dnorm(x, mean = x_bar, sd = std), col = \"black\", lwd = 2, add = TRUE)\n\n# Add labels and legends\nlegend(\"topright\", legend = c(\"Distribution Curve\"),\n       col = c(\"black\"), lwd = 2)\n\n# Reset the plot layout\npar(mfrow = c(1, 1))\n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-19-1.png){width=576}\n:::\n:::\n\n\n\n\n:::\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media $\\mu$ e la deviazione standard $\\sigma$, ed è espresso dalla relazione $\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})$.\n\n## Distribuzioni campionarie di altre statistiche\n\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie.  Ad esempio, la figura seguente mostra l'approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu <- 100\nsigma <- 15\nx <- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny <- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e trovare il massimo punteggio per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_maxes <- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione dei massimi campionari insieme alla distribuzione della popolazione\n\n# Creare il data frame per il grafico\ndata <- data.frame(SampleMaxes = sample_maxes)\ndensity_data <- data.frame(x = x, y = y)\n\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1) +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) \n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-20-1.png){width=576}\n:::\n:::\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\n$$\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n$$\n\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l'approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a $15^2$, abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l'utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza *distorsione*, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu <- 100\nsigma <- 15\nx <- seq(0, 30, length.out = 100)\ny <- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars <- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\n\ndata <- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-21-1.png){width=576}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#> [1] 226\n```\n:::\n\n\n\n\nAbbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo $n-1$ al denominatore.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu <- 100\nsigma <- 15\nx <- seq(0, 30, length.out = 100)\ny <- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza corretta per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars <- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\ndata <- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](08_sampling_distr_files/figure-html/unnamed-chunk-23-1.png){width=576}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#> [1] 226\n```\n:::\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro è chiamata *errore della stima*. Uno stimatore si dice *non distorto* (*unbiased*) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l'errore medio di stima è zero. \n\nIn questo capitolo abbiamo visto che $\\frac{\\sum_{i=1}^n{X_i}}{n}$ è uno stimatore non distorto di $\\mu$ e che $\\frac{\\sum_{i=1}^n{(^2)}}{n-1}$ è uno stimatore non distorto di $\\sigma^2$. Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro. \n\n## Riflessioni Conclusive\n\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell'inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n|Simbolo          | Nome           | È qualcosa che conosciamo?     |\n|:----------------|:-------------|:--------------------|\n|$s$              |Deviazione standard del campione    |Sì, la calcoliamo dai dati grezzi |\n|$\\sigma$         |Deviazione standard della popolazione  | No, tranne in casi particolari o nelle simulazioni  |\n|$\\hat{\\sigma}$  | Stima della deviazione standard della popolazione | Sì, ma non è uguale a $\\sigma$ |\n|$s^2$            | Varianza del campione    |Sì, la calcoliamo dai dati grezzi |\n|$\\sigma^2$       | Varianza della popolazione  | No, tranne in casi particolari o nelle simulazioni  |\n|$\\hat{\\sigma}^2$ | Stima della varianza della popolazione  | Sì, ma non è uguale a $\\sigma^2$  |\n\nUtilizzando le informazioni di un campione casuale di ampiezza $n$:\n\n- La stima migliore che possiamo ottenere per la media $\\mu$ della popolazione è la media del campione $\\bar{Y}$.\n- La stima migliore che possiamo ottenere per la varianza $\\sigma^2$ della popolazione è:\n\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n$$\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.4.2 (2024-10-31)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.2\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] viridis_0.6.5     viridisLite_0.4.2 gridExtra_2.3     patchwork_1.3.0  \n#>  [5] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#>  [9] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#> [13] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#> [17] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#> [21] here_1.0.1       \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#>  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#>  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#> [13] jsonlite_1.8.9    fansi_1.0.6       mnormt_2.1.1      cli_3.6.3        \n#> [17] rlang_1.1.4       munsell_0.5.1     withr_3.0.2       tools_4.4.2      \n#> [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#> [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#> [29] pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.6      glue_1.8.0       \n#> [33] xfun_0.49         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#> [37] nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2\n```\n:::\n\n\n\n\n## Bibliografia {.unnumbered}\n\n\n",
    "supporting": [
      "08_sampling_distr_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}